# 模块三：数据构造方法

> QA数据生成、轨迹采样与质量控制的完整指南

---

## 1. 数据构造的核心挑战

### 1.1 为什么数据如此重要？

Deep Research Agent的性能高度依赖训练数据的质量和多样性：

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        数据决定性能的原因                                        │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  1. 复杂推理能力来自数据                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  模型通过观察大量"思考-行动-观察"的示例来学习                             │   │
│  │  数据中的推理链质量直接决定模型的推理能力                                  │   │
│  │  错误的推理示例会导致模型学习错误的模式                                    │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  2. 任务难度分布决定能力上限                                                     │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  只训练简单问题 → 模型只会解决简单问题                                     │   │
│  │  需要足够多的复杂问题来扩展能力边界                                        │   │
│  │  但太难的问题会导致训练不稳定                                              │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  3. 多样性防止过拟合                                                             │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  单一领域的数据 → 模型只在该领域表现好                                     │   │
│  │  需要覆盖多种问题类型、领域、推理模式                                      │   │
│  │  多样性是泛化能力的基础                                                    │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  4. 现有数据集不够                                                               │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  HotpotQA: 只有2跳推理，太简单                                            │   │
│  │  NQ/TriviaQA: 单跳事实查询                                                │   │
│  │  需要专门构造符合Deep Research复杂度的数据                                 │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 1.2 数据构造的目标

理想的Deep Research训练数据应该具备：

| 维度 | 要求 | 原因 |
|------|------|------|
| **复杂度** | 需要多步推理（5-50步） | 简单问题无法锻炼深度研究能力 |
| **多样性** | 覆盖多领域、多类型 | 防止过拟合，提升泛化 |
| **真实性** | 答案可通过网络搜索验证 | 确保可训练性，避免无解问题 |
| **清晰性** | 问题和答案定义明确 | 便于自动评估和奖励计算 |
| **时效性** | 信息在网上可查到 | 工具调用能获得有效结果 |

### 1.3 数据构造方法全景

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        数据构造方法分类                                          │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  按数据类型分:                                                                   │
│  ├── QA数据: 问题-答案对，用于定义任务目标                                      │
│  │   ├── SailorFog-QA: 知识图谱 + 随机游走                                     │
│  │   ├── WebFrontier: 迭代复杂度升级                                           │
│  │   ├── WebShaper: 形式化驱动                                                 │
│  │   └── E2HQA: Easy-to-Hard演化                                              │
│  │                                                                              │
│  └── 轨迹数据: 完整的推理执行过程，用于SFT                                      │
│      ├── 强模型采样: GPT-4/Claude生成示范                                      │
│      ├── 自我采样: 已训练模型生成轨迹                                          │
│      └── 人工标注: 人类专家标注（成本高，数量少）                               │
│                                                                                 │
│  按方法论分:                                                                     │
│  ├── 图谱驱动: 从结构化知识出发                                                │
│  ├── 文档驱动: 从原始文档出发                                                  │
│  ├── 形式化驱动: 从推理结构出发                                                │
│  └── 演化驱动: 从简单数据出发迭代升级                                          │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 2. 种子数据来源

在介绍各种数据扩展方法之前，首先需要解决一个根本问题：**最初的种子数据从哪里来？**

### 2.1 种子数据的三种类型

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        种子数据类型与来源                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  类型1: 种子QA对 (用于E2HQA、WebFrontier等方法的起点)                            │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  来源:                                                                    │   │
│  │  ├─ 公开QA数据集                                                          │   │
│  │  │   ├─ NaturalQuestions (Google搜索日志)     ~300K QA                   │   │
│  │  │   ├─ TriviaQA (问答网站)                   ~95K QA                    │   │
│  │  │   ├─ HotpotQA (多跳推理)                   ~113K QA                   │   │
│  │  │   ├─ MS MARCO (Bing搜索日志)               ~1M QA                     │   │
│  │  │   └─ SQuAD (阅读理解)                      ~100K QA                   │   │
│  │  │                                                                        │   │
│  │  ├─ 知识库自动生成                                                        │   │
│  │  │   ├─ Wikidata三元组转QA: (爱因斯坦, 出生地, 乌尔姆) → "爱因斯坦出生在哪？"│   │
│  │  │   ├─ Wikipedia信息框提取                                               │   │
│  │  │   └─ 结构化数据库查询结果                                               │   │
│  │  │                                                                        │   │
│  │  └─ 人工标注/众包                                                         │   │
│  │      ├─ 领域专家设计问题                                                   │   │
│  │      └─ 众包平台收集 (Amazon MTurk, Scale AI)                             │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  类型2: 种子实体 (用于SailorFog-QA的图谱构建)                                    │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  来源:                                                                    │   │
│  │  ├─ 通用知识库                                                            │   │
│  │  │   ├─ Wikidata: 1亿+实体，结构化关系                                    │   │
│  │  │   ├─ DBpedia: Wikipedia结构化版本                                      │   │
│  │  │   ├─ Freebase: Google知识图谱前身 (已归档)                             │   │
│  │  │   └─ YAGO: 学术知识库，高质量                                          │   │
│  │  │                                                                        │   │
│  │  ├─ 领域知识库                                                            │   │
│  │  │   ├─ 学术: Semantic Scholar, OpenAlex, DBLP                           │   │
│  │  │   ├─ 医学: UMLS, PubMed                                               │   │
│  │  │   ├─ 金融: Crunchbase, SEC EDGAR                                      │   │
│  │  │   └─ 地理: GeoNames, OpenStreetMap                                    │   │
│  │  │                                                                        │   │
│  │  └─ 动态来源                                                              │   │
│  │      ├─ 新闻网站实体提取 (Google News, Reuters)                           │   │
│  │      └─ 社交媒体热点实体                                                   │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  类型3: 种子文档/语料库 (用于WebFrontier的信息抽取)                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  来源:                                                                    │   │
│  │  ├─ 网页语料                                                              │   │
│  │  │   ├─ Common Crawl: 数十亿网页，开放获取                                │   │
│  │  │   ├─ C4 (Colossal Clean Crawled Corpus): 清洗后的网页                 │   │
│  │  │   └─ RefinedWeb: 高质量过滤的网页                                      │   │
│  │  │                                                                        │   │
│  │  ├─ 学术文档                                                              │   │
│  │  │   ├─ arXiv: 200万+预印本论文                                          │   │
│  │  │   ├─ Semantic Scholar: 2亿+论文元数据                                 │   │
│  │  │   ├─ PubMed: 生物医学文献                                              │   │
│  │  │   └─ ACL Anthology: NLP领域论文                                       │   │
│  │  │                                                                        │   │
│  │  ├─ 书籍                                                                  │   │
│  │  │   ├─ Project Gutenberg: 7万+免费电子书                                │   │
│  │  │   └─ OpenLibrary: 数百万书籍元数据                                     │   │
│  │  │                                                                        │   │
│  │  └─ 结构化数据                                                            │   │
│  │      ├─ Wikipedia: 6000万+文章 (多语言)                                   │   │
│  │      ├─ 政府公开数据 (data.gov等)                                         │   │
│  │      └─ 企业财报、年报                                                     │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 种子数据获取实现

#### 2.2.1 从公开QA数据集获取种子

```python
from datasets import load_dataset

class SeedQACollector:
    """种子QA收集器"""

    def __init__(self):
        self.sources = {
            "natural_questions": self._load_nq,
            "triviaqa": self._load_triviaqa,
            "hotpotqa": self._load_hotpotqa,
        }

    def collect(self, source: str, num_samples: int = 1000) -> List[dict]:
        """从指定来源收集种子QA"""
        if source not in self.sources:
            raise ValueError(f"Unknown source: {source}")
        return self.sources[source](num_samples)

    def _load_nq(self, num_samples: int) -> List[dict]:
        """加载Natural Questions"""
        dataset = load_dataset("natural_questions", split="train")

        seed_qa = []
        for item in dataset:
            if len(seed_qa) >= num_samples:
                break

            # 过滤：只要有短答案的问题
            if item["annotations"]["short_answers"]:
                seed_qa.append({
                    "question": item["question"]["text"],
                    "answer": item["annotations"]["short_answers"][0]["text"],
                    "source": "natural_questions",
                    "complexity": 1  # 初始复杂度
                })

        return seed_qa

    def _load_hotpotqa(self, num_samples: int) -> List[dict]:
        """加载HotpotQA (已有2跳推理)"""
        dataset = load_dataset("hotpot_qa", "fullwiki", split="train")

        seed_qa = []
        for item in dataset:
            if len(seed_qa) >= num_samples:
                break

            seed_qa.append({
                "question": item["question"],
                "answer": item["answer"],
                "source": "hotpotqa",
                "complexity": 2,  # HotpotQA本身是2跳
                "supporting_facts": item["supporting_facts"]
            })

        return seed_qa
```

#### 2.2.2 从知识库生成种子QA

```python
class WikidataQAGenerator:
    """从Wikidata生成种子QA"""

    def __init__(self):
        self.endpoint = "https://query.wikidata.org/sparql"
        self.relation_templates = {
            "P19": ("出生地", "{entity}出生在哪里？"),
            "P20": ("死亡地", "{entity}在哪里去世？"),
            "P69": ("毕业院校", "{entity}毕业于哪所学校？"),
            "P108": ("工作单位", "{entity}在哪里工作？"),
            "P26": ("配偶", "{entity}的配偶是谁？"),
            "P40": ("子女", "{entity}有哪些子女？"),
            "P112": ("创始人", "{entity}是由谁创立的？"),
            "P571": ("成立时间", "{entity}是什么时候成立的？"),
            "P17": ("所在国家", "{entity}位于哪个国家？"),
            "P131": ("所在行政区", "{entity}位于哪个行政区？"),
        }

    def generate_qa(self, num_samples: int = 1000) -> List[dict]:
        """生成QA对"""
        qa_pairs = []

        for relation_id, (relation_name, template) in self.relation_templates.items():
            # 查询具有该关系的实体
            query = f"""
            SELECT ?entity ?entityLabel ?value ?valueLabel WHERE {{
              ?entity wdt:{relation_id} ?value .
              ?entity rdfs:label ?entityLabel .
              ?value rdfs:label ?valueLabel .
              FILTER(LANG(?entityLabel) = "zh" || LANG(?entityLabel) = "en")
              FILTER(LANG(?valueLabel) = "zh" || LANG(?valueLabel) = "en")
            }}
            LIMIT {num_samples // len(self.relation_templates)}
            """

            results = self._execute_query(query)

            for result in results:
                entity = result["entityLabel"]["value"]
                value = result["valueLabel"]["value"]

                qa_pairs.append({
                    "question": template.format(entity=entity),
                    "answer": value,
                    "source": "wikidata",
                    "relation": relation_name,
                    "complexity": 1
                })

        return qa_pairs

    def _execute_query(self, query: str) -> List[dict]:
        """执行SPARQL查询"""
        response = requests.get(
            self.endpoint,
            params={"query": query, "format": "json"},
            headers={"User-Agent": "DeepResearchBot/1.0"}
        )
        return response.json()["results"]["bindings"]
```

#### 2.2.3 从文档语料生成种子

```python
class DocumentSeedGenerator:
    """从文档语料生成种子数据"""

    def __init__(self, llm):
        self.llm = llm

    def generate_from_documents(self, documents: List[str],
                                num_qa_per_doc: int = 3) -> List[dict]:
        """从文档中生成QA对"""
        all_qa = []

        for doc in documents:
            # 1. 提取关键信息
            key_facts = self._extract_key_facts(doc)

            # 2. 为每个事实生成问题
            for fact in key_facts[:num_qa_per_doc]:
                qa = self._fact_to_qa(fact, doc)
                if qa:
                    all_qa.append(qa)

        return all_qa

    def _extract_key_facts(self, document: str) -> List[dict]:
        """从文档中提取关键事实"""
        prompt = f"""从以下文档中提取5-10个关键事实，每个事实应该是一个可验证的陈述。

文档:
{document[:2000]}  # 截断避免过长

请以JSON列表格式返回，每个事实包含:
- fact: 事实描述
- entities: 涉及的实体列表
- type: 事实类型 (人物、事件、数据、关系等)

返回:"""

        response = self.llm.generate(prompt)
        return json.loads(response)

    def _fact_to_qa(self, fact: dict, source_doc: str) -> dict:
        """将事实转换为QA对"""
        prompt = f"""将以下事实转换为一个问答对。

事实: {fact['fact']}
涉及实体: {fact['entities']}

要求:
1. 问题应该自然、清晰
2. 答案应该是事实中的某个具体信息
3. 问题不应该直接包含答案

返回JSON格式:
{{"question": "...", "answer": "..."}}"""

        response = self.llm.generate(prompt)
        qa = json.loads(response)
        qa["source"] = "document_extraction"
        qa["complexity"] = 1
        qa["original_fact"] = fact

        return qa
```

### 2.3 种子数据质量筛选

获取种子数据后，需要进行质量筛选：

```python
class SeedQualityFilter:
    """种子数据质量筛选器"""

    def __init__(self, tools, llm):
        self.tools = tools
        self.llm = llm

    def filter(self, seed_qa: List[dict]) -> List[dict]:
        """筛选高质量种子数据"""
        filtered = []

        for qa in seed_qa:
            # 检查1: 答案可搜索验证
            if not self._is_answer_searchable(qa):
                continue

            # 检查2: 问题不是太简单（LLM不能直接答对）
            if self._llm_can_answer_directly(qa):
                continue

            # 检查3: 问题清晰无歧义
            if not self._is_question_clear(qa):
                continue

            filtered.append(qa)

        return filtered

    def _is_answer_searchable(self, qa: dict) -> bool:
        """检查答案是否可通过搜索找到"""
        results = self.tools.execute({
            "name": "search",
            "arguments": {"query": qa["question"]}
        })

        answer_lower = str(qa["answer"]).lower()
        for result in results[:5]:
            if answer_lower in result.snippet.lower():
                return True
        return False

    def _llm_can_answer_directly(self, qa: dict) -> bool:
        """检查LLM是否能不搜索直接答对"""
        prompt = f"请直接回答，不要搜索: {qa['question']}"
        response = self.llm.generate(prompt, temperature=0)

        # 简单的答案匹配
        return str(qa["answer"]).lower() in response.lower()

    def _is_question_clear(self, qa: dict) -> bool:
        """检查问题是否清晰"""
        prompt = f"""判断以下问题是否清晰、无歧义，且有唯一确定的答案。

问题: {qa["question"]}

返回: YES 或 NO，以及简要理由"""

        response = self.llm.generate(prompt)
        return response.strip().upper().startswith("YES")
```

### 2.4 种子数据来源选择建议

| 应用场景 | 推荐种子来源 | 理由 |
|----------|--------------|------|
| **通用问答** | NQ + TriviaQA | 覆盖广，来自真实用户查询 |
| **多跳推理** | HotpotQA | 已有2跳结构，便于扩展 |
| **学术研究** | arXiv + Semantic Scholar | 领域专业，信息密度高 |
| **时事问答** | 新闻语料 + Wikidata近期实体 | 时效性强 |
| **特定领域** | 领域知识库 + 专业文档 | 领域针对性强 |
| **冷启动** | Wikidata自动生成 | 量大、结构化、易获取 |

### 2.5 数据来源的许可与合规

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        数据许可与合规注意事项                                      │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  开放许可 (可自由使用):                                                           │
│  ├─ Wikidata: CC0 (公共领域)                                                    │
│  ├─ Wikipedia: CC BY-SA                                                         │
│  ├─ Common Crawl: 各网页原始许可                                                │
│  ├─ arXiv: 作者保留版权，但允许学术使用                                          │
│  ├─ Project Gutenberg: 公共领域                                                 │
│  └─ NaturalQuestions, HotpotQA: 学术研究许可                                    │
│                                                                                 │
│  需要注意:                                                                       │
│  ├─ 商业使用可能需要额外授权                                                     │
│  ├─ 某些数据集禁止用于训练竞品模型                                               │
│  ├─ 网页爬取需遵守robots.txt                                                    │
│  └─ 用户数据需要脱敏处理                                                         │
│                                                                                 │
│  最佳实践:                                                                       │
│  ├─ 记录每条数据的来源和许可                                                     │
│  ├─ 使用前检查最新的许可条款                                                     │
│  ├─ 对敏感信息进行脱敏                                                           │
│  └─ 保留数据溯源信息                                                             │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 方法一：SailorFog-QA

### 3.1 核心思想

SailorFog-QA 通过构建知识图谱并在其上随机游走来生成复杂的QA对。核心洞察是：

- **复杂问题 = 图谱中的复杂路径**
- **问题难度 = 路径长度 + 节点模糊度**
- **答案可验证性 = 图谱中存在路径**

### 3.2 阶段一：知识图谱构建

#### 3.2.1 种子实体获取

```python
class SeedEntityCollector:
    """种子实体收集器"""

    def __init__(self, config: dict):
        self.wikidata_endpoint = "https://query.wikidata.org/sparql"
        self.target_domains = config.get("domains", [
            "人物", "组织", "地点", "事件", "作品", "科学概念"
        ])
        self.rarity_threshold = config.get("rarity_threshold", 0.3)

    def collect_seeds(self, num_seeds: int = 1000) -> List[dict]:
        """收集种子实体"""
        seeds = []

        for domain in self.target_domains:
            domain_seeds = self._query_domain_entities(domain)
            # 过滤掉太常见的实体（太容易被模型直接记住）
            rare_seeds = [s for s in domain_seeds if self._is_rare(s)]
            seeds.extend(rare_seeds)

        return seeds[:num_seeds]

    def _query_domain_entities(self, domain: str) -> List[dict]:
        """查询特定领域的实体"""
        # SPARQL查询示例：获取稀有历史人物
        query = """
        SELECT ?entity ?label ?description WHERE {
          ?entity wdt:P31 wd:Q5 .  # 是人类
          ?entity wdt:P106 ?occupation .  # 有职业
          ?entity rdfs:label ?label .
          FILTER(LANG(?label) = "en")
          OPTIONAL { ?entity schema:description ?description . }
          # 排除太著名的实体（如有维基百科页面浏览量过高）
        }
        LIMIT 500
        """

        response = requests.get(
            self.wikidata_endpoint,
            params={"query": query, "format": "json"}
        )
        return self._parse_results(response.json())

    def _is_rare(self, entity: dict) -> bool:
        """判断实体是否足够稀有（不容易被LLM直接记住）"""
        # 检查方法：让LLM直接回答关于该实体的问题
        # 如果LLM无法正确回答，说明实体足够稀有
        test_question = f"Who is {entity['label']}?"
        llm_answer = self.test_llm.generate(test_question)

        # 如果LLM的回答不包含关键信息，认为足够稀有
        return not self._contains_key_info(llm_answer, entity)
```

#### 3.2.2 实体特征提取

```python
class EntityFeatureExtractor:
    """实体特征提取器"""

    def __init__(self, tools: ToolRegistry):
        self.tools = tools

    def extract_features(self, entity: dict) -> dict:
        """提取实体的详细特征"""
        features = {
            "basic_info": entity,
            "attributes": {},
            "relations": [],
            "sources": []
        }

        # 1. 搜索获取基本信息
        search_results = self.tools.execute({
            "name": "search",
            "arguments": {"query": entity["label"]}
        })

        # 2. 访问相关网页获取详细信息
        for result in search_results[:3]:
            content = self.tools.execute({
                "name": "visit",
                "arguments": {
                    "url": result.url,
                    "goal": f"Extract key facts about {entity['label']}"
                }
            })
            features["sources"].append({
                "url": result.url,
                "content": content
            })

        # 3. 从内容中提取结构化特征
        features["attributes"] = self._extract_attributes(features["sources"])
        features["relations"] = self._extract_relations(features["sources"])

        return features

    def _extract_attributes(self, sources: List[dict]) -> dict:
        """从源内容中提取属性"""
        # 使用LLM提取结构化信息
        prompt = f"""从以下内容中提取关键属性信息（如出生日期、地点、职业等）：

{sources}

请以JSON格式返回属性："""

        response = self.llm.generate(prompt)
        return json.loads(response)
```

#### 3.2.3 图谱扩展（随机游走启发）

这是SailorFog-QA的核心创新——使用随机游走思想来扩展图谱：

```python
class KnowledgeGraphBuilder:
    """知识图谱构建器"""

    def __init__(self, config: dict):
        self.max_nodes = config.get("max_nodes", 500)
        self.max_edges = config.get("max_edges", 2000)
        self.p_new = config.get("p_new", 0.7)  # 发现新节点的概率
        self.feature_extractor = EntityFeatureExtractor(config["tools"])

    def build_graph(self, seed_entities: List[dict]) -> nx.DiGraph:
        """构建知识图谱"""
        G = nx.DiGraph()

        # 初始化种子节点
        for entity in seed_entities:
            features = self.feature_extractor.extract_features(entity)
            G.add_node(entity["id"], **features)

        # 随机游走式扩展
        current_node = random.choice(list(G.nodes()))

        for _ in range(self.max_edges):
            if random.random() < self.p_new:
                # 发现新节点
                new_entity = self._discover_related_entity(G, current_node)
                if new_entity and new_entity["id"] not in G:
                    features = self.feature_extractor.extract_features(new_entity)
                    G.add_node(new_entity["id"], **features)
                    # 建立边
                    relation = self._determine_relation(current_node, new_entity)
                    G.add_edge(current_node, new_entity["id"], relation=relation)
                    current_node = new_entity["id"]
            else:
                # 连接到已有节点（创建循环结构）
                existing_nodes = [n for n in G.nodes() if n != current_node]
                if existing_nodes:
                    target = random.choice(existing_nodes)
                    relation = self._find_or_create_relation(current_node, target)
                    if relation:
                        G.add_edge(current_node, target, relation=relation)
                    current_node = target

            if len(G.nodes()) >= self.max_nodes:
                break

        return G

    def _discover_related_entity(self, G: nx.DiGraph, node_id: str) -> dict:
        """发现与当前节点相关的新实体"""
        node_data = G.nodes[node_id]

        # 搜索相关实体
        search_query = f"{node_data['basic_info']['label']} related"
        results = self.tools.execute({
            "name": "search",
            "arguments": {"query": search_query}
        })

        # 从搜索结果中提取新实体
        for result in results:
            entities = self._extract_entities_from_text(result.snippet)
            for entity in entities:
                if entity["id"] not in G:
                    return entity

        return None

    def _determine_relation(self, source: str, target: str) -> str:
        """确定两个实体之间的关系"""
        source_info = self.G.nodes[source]["basic_info"]["label"]
        target_info = target if isinstance(target, str) else target["label"]

        prompt = f"""确定以下两个实体之间的关系：
实体1: {source_info}
实体2: {target_info}

可能的关系类型：出生于、工作于、创作、参与、属于、位于、发生在...
请返回最合适的关系名称："""

        return self.llm.generate(prompt).strip()
```

### 3.3 阶段二：子图采样与QA生成

#### 3.3.1 基于Weisfeiler-Leman的非同构子图采样

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    为什么需要非同构子图采样？                                     │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  问题：随机采样的子图可能结构相似，导致生成重复的问题                             │
│                                                                                 │
│  示例：                                                                          │
│  子图1: A --出生于--> B --位于--> C                                             │
│  子图2: D --出生于--> E --位于--> F                                             │
│  虽然节点不同，但结构同构，会生成相似的问题                                       │
│                                                                                 │
│  解决方案：使用Weisfeiler-Leman算法检测同构性                                    │
│  只保留结构不同的子图，确保问题多样性                                            │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

```python
import networkx as nx
from networkx.algorithms import weisfeiler_lehman_graph_hash

class SubgraphSampler:
    """子图采样器"""

    def __init__(self, graph: nx.DiGraph, config: dict):
        self.graph = graph
        self.min_nodes = config.get("min_nodes", 3)
        self.max_nodes = config.get("max_nodes", 10)
        self.seen_hashes = set()

    def sample_subgraphs(self, num_samples: int) -> List[nx.DiGraph]:
        """采样非同构子图"""
        subgraphs = []

        for _ in range(num_samples * 10):  # 过采样以获得足够的非同构子图
            subgraph = self._random_walk_sample()

            if subgraph is None:
                continue

            # 检查是否与已有子图同构
            graph_hash = weisfeiler_lehman_graph_hash(
                subgraph,
                edge_attr='relation'
            )

            if graph_hash not in self.seen_hashes:
                self.seen_hashes.add(graph_hash)
                subgraphs.append(subgraph)

            if len(subgraphs) >= num_samples:
                break

        return subgraphs

    def _random_walk_sample(self) -> nx.DiGraph:
        """随机游走采样子图"""
        # 随机选择起始节点
        start_node = random.choice(list(self.graph.nodes()))

        # 随机游走收集节点
        visited = {start_node}
        current = start_node
        num_nodes = random.randint(self.min_nodes, self.max_nodes)

        while len(visited) < num_nodes:
            neighbors = list(self.graph.neighbors(current)) + \
                        list(self.graph.predecessors(current))

            if not neighbors:
                break

            next_node = random.choice(neighbors)
            visited.add(next_node)
            current = next_node

        if len(visited) < self.min_nodes:
            return None

        # 提取子图
        return self.graph.subgraph(visited).copy()
```

#### 3.3.2 轨道节点分析与问题焦点选择

```python
class OrbitAnalyzer:
    """轨道节点分析器

    轨道节点：在图同构映射下不等价的节点
    将问题焦点均匀分布在轨道节点上可以增加问题多样性
    """

    def find_orbit_nodes(self, subgraph: nx.DiGraph) -> List[List[str]]:
        """找到子图中的轨道分组"""
        # 简化实现：基于节点的结构特征分组
        node_features = {}

        for node in subgraph.nodes():
            features = (
                subgraph.in_degree(node),
                subgraph.out_degree(node),
                self._get_neighbor_pattern(subgraph, node)
            )
            if features not in node_features:
                node_features[features] = []
            node_features[features].append(node)

        return list(node_features.values())

    def _get_neighbor_pattern(self, graph: nx.DiGraph, node: str) -> tuple:
        """获取节点的邻居模式"""
        in_relations = tuple(sorted([
            graph.edges[pred, node].get('relation', '')
            for pred in graph.predecessors(node)
        ]))
        out_relations = tuple(sorted([
            graph.edges[node, succ].get('relation', '')
            for succ in graph.neighbors(node)
        ]))
        return (in_relations, out_relations)

    def select_focus_node(self, subgraph: nx.DiGraph,
                          previous_orbits: List[int]) -> str:
        """选择问题焦点节点，尽量覆盖不同轨道"""
        orbits = self.find_orbit_nodes(subgraph)

        # 选择被选中次数最少的轨道
        orbit_counts = [0] * len(orbits)
        for prev_orbit in previous_orbits:
            if prev_orbit < len(orbit_counts):
                orbit_counts[prev_orbit] += 1

        min_count = min(orbit_counts)
        candidates = [i for i, c in enumerate(orbit_counts) if c == min_count]

        selected_orbit = random.choice(candidates)
        return random.choice(orbits[selected_orbit])
```

#### 3.3.3 问题生成

```python
class QuestionGenerator:
    """问题生成器"""

    def __init__(self, llm):
        self.llm = llm

    def generate_qa(self, subgraph: nx.DiGraph,
                    focus_node: str,
                    apply_fog: bool = True) -> dict:
        """生成QA对"""
        # 1. 构建子图描述
        graph_description = self._describe_subgraph(subgraph, focus_node)

        # 2. 生成基础问题
        prompt = f"""基于以下知识图谱信息，生成一个需要多步推理才能回答的问题。
问题的答案应该是节点 [{focus_node}] 的某个属性。

知识图谱:
{graph_description}

要求:
1. 问题应该需要遍历多个节点才能找到答案
2. 问题应该使用自然语言，不要暴露图谱结构
3. 问题应该有唯一确定的答案

请生成问题:"""

        question = self.llm.generate(prompt)

        # 3. 获取答案
        answer = self._get_answer(subgraph, focus_node)

        # 4. 应用信息模糊化
        if apply_fog:
            question = self._apply_fog(question, subgraph)

        return {
            "question": question,
            "answer": answer,
            "subgraph": nx.node_link_data(subgraph),
            "focus_node": focus_node
        }

    def _describe_subgraph(self, subgraph: nx.DiGraph,
                           focus_node: str) -> str:
        """生成子图的自然语言描述"""
        descriptions = []

        for u, v, data in subgraph.edges(data=True):
            u_label = subgraph.nodes[u].get("basic_info", {}).get("label", u)
            v_label = subgraph.nodes[v].get("basic_info", {}).get("label", v)
            relation = data.get("relation", "相关")
            descriptions.append(f"- {u_label} --[{relation}]--> {v_label}")

        return "\n".join(descriptions)

    def _apply_fog(self, question: str, subgraph: nx.DiGraph) -> str:
        """应用信息模糊化"""
        prompt = f"""将以下问题中的具体信息替换为模糊描述，增加问题难度：

原问题: {question}

模糊化规则:
- 具体年份 → "某个时期"/"X年代"
- 具体地点 → "某个地方"/"一个城市"
- 人名 → "某人"/"一位..."
- 组织名 → "某组织"/"一家公司"

但要保证：
1. 问题仍然有唯一答案
2. 模糊化的信息可以通过搜索找到

模糊化后的问题:"""

        return self.llm.generate(prompt)
```

### 3.4 SailorFog V1 vs V2 的关键区别

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    SailorFog V1 vs V2 对比                                       │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  V1: 树状/无环结构                                                               │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │          A                                                               │   │
│  │         /|\                                                              │   │
│  │        B C D                                                             │   │
│  │       /|   |\                                                            │   │
│  │      E F   G H                                                           │   │
│  │                                                                          │   │
│  │  特点:                                                                    │   │
│  │  - Easy-to-Hard: 从根节点开始，逐步扩展                                   │   │
│  │  - 推理路径唯一                                                           │   │
│  │  - 问题难度 ≈ 路径长度                                                    │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  V2: 密集互联/有环结构                                                           │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │          A ←──┐                                                          │   │
│  │         /|\   │                                                          │   │
│  │        B─C─D  │                                                          │   │
│  │       /|╲ |╱\ │                                                          │   │
│  │      E─F─G─H──┘                                                          │   │
│  │                                                                          │   │
│  │  特点:                                                                    │   │
│  │  - 主动创建节点间连接，形成循环                                            │   │
│  │  - 多条推理路径到达同一答案                                               │   │
│  │  - 更接近真实知识的网状结构                                               │   │
│  │  - 问题难度 = 路径长度 + 路径选择复杂度                                    │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  性能对比 (BrowseComp基准):                                                      │
│  - V1: ~28% 准确率                                                              │
│  - V2: ~35% 准确率 (+7%)                                                        │
│                                                                                 │
│  原因分析:                                                                       │
│  - V2的密集结构让模型学会在多条路径中选择                                        │
│  - 循环结构迫使模型学会信息整合和去重                                            │
│  - 更接近真实研究任务的复杂度                                                    │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 方法二：WebFrontier

### 4.1 核心思想

WebFrontier 通过**迭代复杂度升级**来生成复杂问题：

- 从简单的种子QA开始
- 每轮通过四种操作增加复杂度
- 使用质量控制确保问题有效

### 4.2 三阶段工作流

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    WebFrontier 完整流程                                          │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  阶段1: 种子数据生成                                                             │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │                                                                          │   │
│  │  输入: 多样化语料库                                                       │   │
│  │  ├── 网页 (Common Crawl)                                                 │   │
│  │  ├── 学术论文 (arXiv, Semantic Scholar)                                  │   │
│  │  └── 电子书 (Gutenberg)                                                  │   │
│  │                    │                                                      │   │
│  │                    ▼                                                      │   │
│  │  Summary Agent: 预处理和蒸馏                                              │   │
│  │  - 提取关键实体和事实                                                     │   │
│  │  - 识别实体间关系                                                         │   │
│  │  - 生成结构化摘要                                                         │   │
│  │                    │                                                      │   │
│  │                    ▼                                                      │   │
│  │  组合单元: 关联主题                                                       │   │
│  │  - 聚类相关实体                                                           │   │
│  │  - 建立跨文档连接                                                         │   │
│  │                    │                                                      │   │
│  │                    ▼                                                      │   │
│  │  输出: 种子QA对 (简单，1-2跳)                                             │   │
│  │                                                                          │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                      │                                          │
│                                      ▼                                          │
│  阶段2: 迭代复杂度升级 (核心)                                                    │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │                                                                          │   │
│  │  for iteration in range(N):                                              │   │
│  │      for qa in current_qa_set:                                           │   │
│  │          # 随机选择升级操作                                               │   │
│  │          operation = random.choice([                                      │   │
│  │              "知识扩展",  # 搜索相关信息扩大范围                           │   │
│  │              "概念抽象",  # 提炼高层概念                                   │   │
│  │              "事实基础",  # 多源验证                                       │   │
│  │              "计算公式化" # 添加计算需求                                   │   │
│  │          ])                                                               │   │
│  │          new_qa = ItemWriter.upgrade(qa, operation)                       │   │
│  │          if quality_check(new_qa):                                        │   │
│  │              current_qa_set.add(new_qa)                                   │   │
│  │                                                                          │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                      │                                          │
│                                      ▼                                          │
│  阶段3: 严格质量控制                                                             │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │                                                                          │   │
│  │  过滤器1: 基线模式测试                                                    │   │
│  │  - 让LLM不用工具直接回答                                                  │   │
│  │  - 如果能正确回答 → 太简单 → 丢弃                                         │   │
│  │                                                                          │   │
│  │  过滤器2: 工具模式测试                                                    │   │
│  │  - 让LLM使用工具回答                                                      │   │
│  │  - 如果不能正确回答 → 可能问题有误 → 人工检查                             │   │
│  │                                                                          │   │
│  │  过滤器3: 相似度检查                                                      │   │
│  │  - 与已有问题计算相似度                                                   │   │
│  │  - 如果太相似 → 丢弃                                                      │   │
│  │                                                                          │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 4.3 四种升级操作详解

```python
class ItemWriter:
    """问题复杂度升级器"""

    def __init__(self, tools: ToolRegistry, llm):
        self.tools = tools
        self.llm = llm

    def upgrade(self, qa: dict, operation: str) -> dict:
        """根据指定操作升级QA复杂度"""
        if operation == "知识扩展":
            return self._knowledge_expansion(qa)
        elif operation == "概念抽象":
            return self._concept_abstraction(qa)
        elif operation == "事实基础":
            return self._fact_grounding(qa)
        elif operation == "计算公式化":
            return self._computational_formulation(qa)
        else:
            raise ValueError(f"Unknown operation: {operation}")

    def _knowledge_expansion(self, qa: dict) -> dict:
        """知识扩展：搜索相关信息扩大问题范围"""
        # 1. 从问题中提取关键实体
        entities = self._extract_entities(qa["question"])

        # 2. 搜索相关信息
        for entity in entities:
            search_results = self.tools.execute({
                "name": "search",
                "arguments": {"query": f"{entity} related facts"}
            })

            # 3. 找到可以关联的新信息
            new_facts = self._extract_linkable_facts(search_results, qa)

            if new_facts:
                # 4. 扩展问题
                new_question = self._expand_question(qa["question"], new_facts)
                return {
                    "question": new_question,
                    "answer": qa["answer"],  # 答案不变
                    "complexity": qa.get("complexity", 1) + 1,
                    "operation": "knowledge_expansion"
                }

        return qa  # 无法扩展，返回原问题

    def _concept_abstraction(self, qa: dict) -> dict:
        """概念抽象：将具体概念替换为更抽象的描述"""
        prompt = f"""将以下问题中的具体概念替换为更抽象的描述，
使得回答问题需要先推理出具体概念。

原问题: {qa["question"]}
答案: {qa["answer"]}

要求:
1. 新问题的答案必须和原问题相同
2. 抽象后的描述必须能唯一确定原概念
3. 新问题应该更难直接回答

示例:
原问题: "特斯拉2024年生产了多少辆汽车？"
新问题: "这家由南非出生的企业家创立的电动车公司在2024年生产了多少辆汽车？"

新问题:"""

        new_question = self.llm.generate(prompt)

        return {
            "question": new_question,
            "answer": qa["answer"],
            "complexity": qa.get("complexity", 1) + 1,
            "operation": "concept_abstraction"
        }

    def _fact_grounding(self, qa: dict) -> dict:
        """事实基础：要求从多个来源验证信息"""
        prompt = f"""修改以下问题，使其需要从多个来源验证信息。

原问题: {qa["question"]}

修改方式:
1. 添加"根据官方数据"/"多个来源确认"等要求
2. 或要求比较不同来源的说法

新问题:"""

        new_question = self.llm.generate(prompt)

        return {
            "question": new_question,
            "answer": qa["answer"],
            "complexity": qa.get("complexity", 1) + 0.5,
            "operation": "fact_grounding"
        }

    def _computational_formulation(self, qa: dict) -> dict:
        """计算公式化：添加需要计算的需求"""
        # 检查答案是否是数值或可以转化为数值
        if not self._is_numeric_answer(qa["answer"]):
            return qa  # 非数值答案，不适合计算公式化

        prompt = f"""将以下问题改写为需要计算才能得到答案的形式。

原问题: {qa["question"]}
原答案: {qa["answer"]}

改写方式:
- 如果答案是总数，可以改为问增长率/变化量
- 如果答案是单个值，可以改为问多个值的总和/平均
- 添加单位换算需求

新问题和计算方法:"""

        result = self.llm.generate(prompt)
        new_question, calculation = self._parse_computational_result(result)

        return {
            "question": new_question,
            "answer": qa["answer"],
            "calculation": calculation,
            "complexity": qa.get("complexity", 1) + 1,
            "operation": "computational_formulation"
        }
```

### 4.4 质量控制实现

```python
class QualityController:
    """质量控制器"""

    def __init__(self, tools: ToolRegistry, llm):
        self.tools = tools
        self.llm = llm
        self.embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
        self.existing_embeddings = []

    def check_quality(self, qa: dict) -> Tuple[bool, str]:
        """检查QA质量，返回(是否通过, 原因)"""

        # 检查1: 基线测试（无工具是否能回答）
        if self._can_answer_without_tools(qa):
            return False, "问题太简单，无需工具即可回答"

        # 检查2: 工具测试（有工具是否能正确回答）
        if not self._can_answer_with_tools(qa):
            return False, "使用工具也无法正确回答，可能问题有误"

        # 检查3: 相似度检查
        if self._is_too_similar(qa):
            return False, "与已有问题太相似"

        # 检查4: 答案可验证性
        if not self._answer_is_verifiable(qa):
            return False, "答案无法通过搜索验证"

        return True, "通过所有检查"

    def _can_answer_without_tools(self, qa: dict) -> bool:
        """测试无工具是否能正确回答"""
        prompt = f"""请直接回答以下问题，不要搜索：

{qa["question"]}

答案:"""

        response = self.llm.generate(prompt, temperature=0)
        return self._check_answer(response, qa["answer"])

    def _can_answer_with_tools(self, qa: dict) -> bool:
        """测试有工具是否能正确回答"""
        # 运行Agent尝试回答
        agent_result = self._run_agent(qa["question"])
        return self._check_answer(agent_result, qa["answer"])

    def _is_too_similar(self, qa: dict, threshold: float = 0.85) -> bool:
        """检查与已有问题是否太相似"""
        qa_embedding = self.embedding_model.encode(qa["question"])

        for existing_emb in self.existing_embeddings:
            similarity = np.dot(qa_embedding, existing_emb) / \
                        (np.linalg.norm(qa_embedding) * np.linalg.norm(existing_emb))
            if similarity > threshold:
                return True

        # 添加到已有集合
        self.existing_embeddings.append(qa_embedding)
        return False

    def _answer_is_verifiable(self, qa: dict) -> bool:
        """检查答案是否可通过搜索验证"""
        search_results = self.tools.execute({
            "name": "search",
            "arguments": {"query": qa["question"]}
        })

        # 检查搜索结果中是否包含答案
        answer_str = str(qa["answer"]).lower()
        for result in search_results:
            if answer_str in result.snippet.lower():
                return True

        return False
```

---

## 5. 方法三：WebShaper

### 5.1 核心思想

WebShaper 使用**形式化方法**来精确控制问题的推理结构：

- 将问题建模为**知识投影（Knowledge Projection）**操作
- 通过形式化语言精确定义推理链
- 保证生成的问题具有可控的复杂度

### 5.2 知识投影形式化定义

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    Knowledge Projection 形式化定义                               │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  基本定义:                                                                       │
│  - E: 实体全集（所有可能的实体）                                                 │
│  - R ⊆ E × E: 关系子空间（具有特定关系的实体对）                                │
│  - R(V): 关系投影，R(V) = {u | ∃v ∈ V, (u,v) ∈ R}                              │
│                                                                                 │
│  示例:                                                                           │
│  - E = {所有人、所有城市、所有年份...}                                           │
│  - R_born = "出生于"关系                                                        │
│  - R_born({北京}) = 所有出生于北京的人                                          │
│                                                                                 │
│  复合操作:                                                                       │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  1. R-Union (处理不确定性):                                              │   │
│  │     R({2000}) ∪ R({2001}) ∪ ... ∪ R({2010})                              │   │
│  │     = 2000-2010年间的所有实体                                             │   │
│  │                                                                          │   │
│  │  2. Intersection (满足多条件):                                            │   │
│  │     R₁({清华}) ∩ R₂({计算机})                                             │   │
│  │     = 在清华学习且专业是计算机的人                                        │   │
│  │                                                                          │   │
│  │  3. Chain (推理链):                                                       │   │
│  │     R₂(R₁({X}))                                                           │   │
│  │     = 先找到与X有R₁关系的实体，再找与这些实体有R₂关系的                   │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  三元组表示:                                                                     │
│  [X, r, S] 表示"X与S有关系r"                                                    │
│  - X: 变量（V@前缀）或常量（C@前缀）                                            │
│  - r: 关系名称                                                                  │
│  - S: 变量或常量                                                                │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 5.3 形式化问题示例

```
自然语言问题:
"有哪些球员在1966年成立的东德足球队效力，
 并且在2004-05赛季出场，且出生于90年代？"

形式化表示:
q(T) ≜ ?T s.t. [
    [V@T, playIn, V@X],           # T在X队效力
    [V@T, playAt, C@2004_05],     # T在2004-05赛季出场
    [V@T, bornIn, C@90s],         # T出生于90年代
    [V@X, foundIn, C@1966],       # X成立于1966年
    [V@X, isA, C@East_German_football_team]  # X是东德足球队
]

推理链分析:
1. 找到成立于1966年的东德足球队 X
2. 找到在X队效力的球员 T
3. 过滤：T在2004-05赛季出场
4. 过滤：T出生于90年代
5. 返回满足所有条件的 T
```

### 5.4 Layer-wise 扩展策略

```python
class LayerwiseExpander:
    """Layer-wise问题扩展器"""

    def __init__(self, llm, knowledge_base):
        self.llm = llm
        self.kb = knowledge_base

    def expand_question(self, base_question: dict) -> dict:
        """Layer-wise扩展问题"""
        # 1. 解析基础问题的形式化表示
        formal_repr = self._parse_formal(base_question)

        # 2. 找到所有叶子常量
        leaf_constants = self._find_leaf_constants(formal_repr)

        # 3. 对每个叶子常量进行扩展
        for constant in leaf_constants:
            # 构建子问题：以该常量为答案的问题
            sub_question = self._build_sub_question(constant)

            if sub_question:
                # 合并到原问题
                formal_repr = self._merge_question(formal_repr, sub_question, constant)

        # 4. 转换回自然语言
        new_question = self._formal_to_natural(formal_repr)

        return {
            "question": new_question,
            "answer": base_question["answer"],  # 答案保持不变
            "formal_repr": formal_repr
        }

    def _find_leaf_constants(self, formal_repr: List[list]) -> List[str]:
        """找到形式化表示中的叶子常量"""
        all_constants = set()
        used_in_relation = set()

        for triple in formal_repr:
            x, r, s = triple
            if x.startswith("C@"):
                all_constants.add(x)
            if s.startswith("C@"):
                all_constants.add(s)
            if x.startswith("V@"):
                used_in_relation.add(x)

        # 叶子常量：没有被变量引用的常量
        return [c for c in all_constants if c not in used_in_relation]

    def _build_sub_question(self, constant: str) -> dict:
        """构建以常量为答案的子问题"""
        # 从知识库中查找关于该常量的信息
        entity = constant.replace("C@", "")
        facts = self.kb.get_facts_about(entity)

        if not facts:
            return None

        # 选择一个事实构建子问题
        fact = random.choice(facts)

        return {
            "formal": [
                [f"V@{entity}", fact["relation"], f"C@{fact['value']}"]
            ],
            "natural": f"满足{fact['description']}的实体"
        }

    def _merge_question(self, base: List[list], sub: dict,
                        constant: str) -> List[list]:
        """合并子问题到基础问题"""
        # 将常量替换为变量，添加新的约束
        new_var = f"V@{constant.replace('C@', '')}"

        # 替换所有引用该常量的地方
        merged = []
        for triple in base:
            new_triple = []
            for item in triple:
                if item == constant:
                    new_triple.append(new_var)
                else:
                    new_triple.append(item)
            merged.append(new_triple)

        # 添加子问题的约束
        merged.extend(sub["formal"])

        return merged
```

### 5.5 为什么Layer-wise优于其他策略？

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    三种扩展策略对比                                              │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  策略1: Random Structure (随机结构)                                              │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  方法: 随机添加常量和关系                                                 │   │
│  │                                                                          │   │
│  │  问题示例:                                                                │   │
│  │  "找到在城市A出生的人，城市A建于1900年"                                   │   │
│  │   └─ 添加: "城市A有一座建于1950年的桥"                                    │   │
│  │                                                                          │   │
│  │  ❌ 问题: "桥"与答案无关，是冗余信息                                      │   │
│  │  ❌ 结果: 增加了干扰但没有增加有效推理深度                                │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  策略2: Sequential Structure (顺序结构)                                          │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  方法: 构建线性推理链                                                     │   │
│  │                                                                          │   │
│  │  问题示例:                                                                │   │
│  │  "找到在城市A出生的人"                                                    │   │
│  │   └─ 扩展: "城市A是国家B的首都"                                           │   │
│  │       └─ 扩展: "国家B在大洲C"                                             │   │
│  │           └─ 但同时添加: "目标人物毕业于大洲C的一所大学"                   │   │
│  │                                                                          │   │
│  │  ❌ 问题: 存在"捷径"——可以直接从大洲C推理，跳过中间步骤                   │   │
│  │  ❌ 结果: 模型可能学会走捷径，而不是完整推理                              │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
│  策略3: Layer-wise Structure (层级结构) ✓                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  方法: 层级遍历叶子常量，逐层扩展                                         │   │
│  │                                                                          │   │
│  │  问题示例:                                                                │   │
│  │  原问题 q^n(T): "找到出生于城市A且工作于公司B的人T"                        │   │
│  │                                                                          │   │
│  │  层级1叶子: {城市A, 公司B}                                                │   │
│  │  扩展城市A: "城市A位于以wine闻名的地区"                                    │   │
│  │  扩展公司B: "公司B由某诺贝尔奖得主创立"                                    │   │
│  │                                                                          │   │
│  │  新问题 q^(n+1)(T): "找到出生于某wine产区城市且工作于                       │   │
│  │                     某诺贝尔奖得主创立公司的人T"                           │   │
│  │                                                                          │   │
│  │  ✅ 关键: q^(n+1)(T) 与 q^n(T) 有相同答案                                │   │
│  │  ✅ 没有冗余信息，没有推理捷径                                            │   │
│  │  ✅ 复杂度线性增加，完全可控                                              │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 6. 方法四：E2HQA

### 6.1 核心思想

E2HQA (Easy-to-Hard Question Answering) 是一种简单高效的方法：

- 从已有的简单QA数据开始
- 通过实体替换迭代增加复杂度
- 保持答案不变

### 6.2 完整实现

```python
class E2HQAGenerator:
    """E2HQA问题生成器"""

    def __init__(self, tools: ToolRegistry, llm):
        self.tools = tools
        self.llm = llm

    def evolve_question(self, simple_qa: dict,
                        num_iterations: int = 3) -> dict:
        """从简单问题演化到复杂问题"""
        current_qa = simple_qa.copy()

        for i in range(num_iterations):
            # 1. 从问题中提取可替换的实体
            entities = self._extract_entities(current_qa["question"])

            if not entities:
                break

            # 2. 选择一个实体进行替换
            entity = random.choice(entities)

            # 3. 搜索该实体的相关信息
            related_info = self._search_entity_info(entity)

            if not related_info:
                continue

            # 4. 构建替换描述
            replacement = self._build_replacement(entity, related_info)

            # 5. 替换实体，生成新问题
            new_question = self._replace_entity(
                current_qa["question"],
                entity,
                replacement
            )

            current_qa = {
                "question": new_question,
                "answer": simple_qa["answer"],  # 答案始终不变
                "evolution_steps": current_qa.get("evolution_steps", []) + [{
                    "entity": entity,
                    "replacement": replacement,
                    "related_info": related_info
                }]
            }

        return current_qa

    def _extract_entities(self, question: str) -> List[str]:
        """提取问题中的命名实体"""
        prompt = f"""从以下问题中提取所有命名实体（人名、地名、组织名、作品名等）：

问题: {question}

请以JSON列表格式返回实体:"""

        response = self.llm.generate(prompt)
        return json.loads(response)

    def _search_entity_info(self, entity: str) -> dict:
        """搜索实体的相关信息"""
        search_results = self.tools.execute({
            "name": "search",
            "arguments": {"query": entity}
        })

        if not search_results:
            return None

        # 提取有用的属性
        prompt = f"""从以下搜索结果中提取关于"{entity}"的关键属性
（如出生日期、创立时间、所属类别、关联人物等）：

搜索结果:
{search_results}

请以JSON格式返回属性:"""

        response = self.llm.generate(prompt)
        return json.loads(response)

    def _build_replacement(self, entity: str, info: dict) -> str:
        """构建实体的替换描述"""
        prompt = f"""为实体"{entity}"构建一个间接描述，使用以下信息：

实体信息: {info}

要求:
1. 描述应该能唯一确定该实体
2. 不要直接提到实体名称
3. 使用自然的表达方式

示例:
- "村上春树" → "毕业于早稻田大学的日本著名作家"
- "特斯拉" → "由马斯克担任CEO的电动车公司"

替换描述:"""

        return self.llm.generate(prompt)

    def _replace_entity(self, question: str, entity: str,
                        replacement: str) -> str:
        """在问题中替换实体"""
        # 简单替换
        return question.replace(entity, replacement)
```

### 6.3 演化示例

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    E2HQA 演化示例                                                │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  初始问题 (1跳):                                                                 │
│  Q: "村上春树出生于哪一年？"                                                     │
│  A: "1949年"                                                                    │
│                                                                                 │
│  ─────────────────────────────────────────────────────────────────────────────  │
│                                                                                 │
│  演化轮次1:                                                                      │
│  选择实体: "村上春树"                                                            │
│  搜索信息: {毕业院校: "早稻田大学", 职业: "作家", 国籍: "日本"}                   │
│  替换描述: "毕业于早稻田大学的著名日本作家"                                       │
│                                                                                 │
│  新问题 (2跳):                                                                   │
│  Q: "毕业于早稻田大学的著名日本作家出生于哪一年？"                                │
│  A: "1949年" (不变)                                                             │
│                                                                                 │
│  ─────────────────────────────────────────────────────────────────────────────  │
│                                                                                 │
│  演化轮次2:                                                                      │
│  选择实体: "早稻田大学"                                                          │
│  搜索信息: {创立时间: "1882年", 类型: "私立大学", 位置: "东京"}                   │
│  替换描述: "1882年创立的日本著名私立大学"                                         │
│                                                                                 │
│  新问题 (3跳):                                                                   │
│  Q: "毕业于1882年创立的日本著名私立大学的著名日本作家出生于哪一年？"              │
│  A: "1949年" (不变)                                                             │
│                                                                                 │
│  ─────────────────────────────────────────────────────────────────────────────  │
│                                                                                 │
│  演化轮次3:                                                                      │
│  选择实体: "1882年"                                                              │
│  搜索信息: {同年事件: "德国三皇同盟成立", 中国: "清朝光绪八年"}                   │
│  替换描述: "德国三皇同盟成立的那一年"                                             │
│                                                                                 │
│  最终问题 (4跳):                                                                 │
│  Q: "毕业于德国三皇同盟成立那年创立的日本著名私立大学的                           │
│      著名日本作家出生于哪一年？"                                                  │
│  A: "1949年" (不变)                                                             │
│                                                                                 │
│  推理链: 1882年 → 早稻田大学 → 村上春树 → 1949年                                 │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 7. 轨迹采样与质量过滤

### 7.1 轨迹采样方法

```python
class TrajectorySampler:
    """轨迹采样器"""

    def __init__(self, config: dict):
        self.teacher_model = config["teacher_model"]  # GPT-4, Claude等
        self.tools = config["tools"]
        self.max_steps = config.get("max_steps", 50)
        self.num_samples_per_question = config.get("num_samples", 3)

    def sample_trajectories(self, qa_dataset: List[dict]) -> List[dict]:
        """为QA数据集采样轨迹"""
        trajectories = []

        for qa in qa_dataset:
            # 对每个问题采样多条轨迹
            for _ in range(self.num_samples_per_question):
                trajectory = self._sample_single(qa)
                if trajectory:
                    trajectories.append(trajectory)

        return trajectories

    def _sample_single(self, qa: dict) -> dict:
        """采样单条轨迹"""
        question = qa["question"]
        answer = qa["answer"]
        messages = [{"role": "user", "content": question}]
        trajectory = []

        for step in range(self.max_steps):
            # 生成think和action
            response = self.teacher_model.generate(
                messages,
                temperature=0.7  # 采样需要一定随机性
            )
            trajectory.append({
                "role": "assistant",
                "content": response
            })

            # 检查是否完成
            if "<answer>" in response:
                extracted_answer = self._extract_answer(response)
                is_correct = self._check_answer(extracted_answer, answer)

                return {
                    "question": question,
                    "answer": answer,
                    "trajectory": trajectory,
                    "is_correct": is_correct,
                    "num_steps": step + 1
                }

            # 执行工具调用
            tool_call = self._parse_tool_call(response)
            if tool_call:
                observation = self.tools.execute(tool_call)
                messages.append({"role": "assistant", "content": response})
                messages.append({
                    "role": "user",
                    "content": f"<tool_response>{observation}</tool_response>"
                })
                trajectory.append({
                    "role": "tool",
                    "content": observation
                })
            else:
                # 格式错误，中断采样
                return None

        # 达到最大步数
        return None
```

### 7.2 三阶段漏斗式过滤

```python
class TrajectoryFilter:
    """轨迹过滤器"""

    def __init__(self, config: dict):
        self.min_steps = config.get("min_steps", 10)
        self.min_tool_calls = config.get("min_tool_calls", 5)
        self.max_tokens = config.get("max_tokens", 64000)
        self.ngram_n = config.get("ngram_n", 10)
        self.max_ngram_repeat = config.get("max_ngram_repeat", 4)
        self.judge_model = config["judge_model"]

    def filter(self, trajectories: List[dict]) -> List[dict]:
        """三阶段过滤"""
        # 阶段1: 有效性控制
        valid = self._validity_filter(trajectories)
        print(f"有效性过滤: {len(trajectories)} -> {len(valid)}")

        # 阶段2: 正确性验证
        correct = self._correctness_filter(valid)
        print(f"正确性过滤: {len(valid)} -> {len(correct)}")

        # 阶段3: 质量评估
        high_quality = self._quality_filter(correct)
        print(f"质量过滤: {len(correct)} -> {len(high_quality)}")

        return high_quality

    def _validity_filter(self, trajectories: List[dict]) -> List[dict]:
        """阶段1: 有效性控制"""
        valid = []

        for traj in trajectories:
            # 检查1: 格式正确性
            if not self._check_format(traj):
                continue

            # 检查2: 长度限制
            total_tokens = self._count_tokens(traj)
            if total_tokens > self.max_tokens:
                continue

            # 检查3: 复杂度要求
            num_steps = len([t for t in traj["trajectory"] if t["role"] == "assistant"])
            num_tool_calls = len([t for t in traj["trajectory"] if t["role"] == "tool"])

            if num_steps < self.min_steps or num_tool_calls < self.min_tool_calls:
                continue

            # 检查4: n-gram重复检测
            if self._has_excessive_repetition(traj):
                continue

            valid.append(traj)

        return valid

    def _correctness_filter(self, trajectories: List[dict]) -> List[dict]:
        """阶段2: 正确性验证"""
        correct = []

        for traj in trajectories:
            # 使用LLM-as-Judge验证答案
            is_correct = self._verify_answer(
                traj["question"],
                traj["answer"],
                self._extract_final_answer(traj)
            )

            if is_correct:
                correct.append(traj)

        return correct

    def _quality_filter(self, trajectories: List[dict]) -> List[dict]:
        """阶段3: 质量评估"""
        high_quality = []

        for traj in trajectories:
            quality_score = self._evaluate_quality(traj)
            if quality_score >= 0.7:  # 质量阈值
                traj["quality_score"] = quality_score
                high_quality.append(traj)

        return high_quality

    def _evaluate_quality(self, traj: dict) -> float:
        """评估轨迹质量"""
        prompt = f"""评估以下研究轨迹的质量（0-1分）：

问题: {traj["question"]}

轨迹:
{self._format_trajectory(traj["trajectory"])}

评估维度:
1. 逻辑连贯性: 推理步骤是否清晰合理
2. 无幻觉: 是否有编造信息的情况
3. 工具使用合理性: 工具调用是否必要和有效
4. 信息非冗余性: 是否有无效的重复搜索

请给出总体评分(0-1)和简要理由:"""

        response = self.judge_model.generate(prompt)
        return self._parse_score(response)

    def _has_excessive_repetition(self, traj: dict) -> bool:
        """检测n-gram重复"""
        text = " ".join([t["content"] for t in traj["trajectory"]])
        words = text.split()

        ngram_counts = {}
        for i in range(len(words) - self.ngram_n + 1):
            ngram = tuple(words[i:i+self.ngram_n])
            ngram_counts[ngram] = ngram_counts.get(ngram, 0) + 1

        max_count = max(ngram_counts.values()) if ngram_counts else 0
        return max_count > self.max_ngram_repeat
```

### 7.3 轨迹格式化

```python
def format_trajectory_for_training(trajectory: dict) -> dict:
    """将轨迹格式化为训练数据格式"""
    messages = []

    # 系统提示
    messages.append({
        "role": "system",
        "content": SYSTEM_PROMPT
    })

    # 用户问题
    messages.append({
        "role": "user",
        "content": trajectory["question"]
    })

    # 轨迹内容
    for item in trajectory["trajectory"]:
        if item["role"] == "assistant":
            messages.append({
                "role": "assistant",
                "content": item["content"]
            })
        elif item["role"] == "tool":
            messages.append({
                "role": "user",
                "content": f"<tool_response>{item['content']}</tool_response>"
            })

    # 创建loss mask
    loss_mask = []
    for msg in messages:
        if msg["role"] == "assistant":
            # assistant消息需要计算loss
            loss_mask.append(True)
        else:
            # 其他消息（包括tool_response）不计算loss
            loss_mask.append(False)

    return {
        "messages": messages,
        "loss_mask": loss_mask,
        "metadata": {
            "question": trajectory["question"],
            "answer": trajectory["answer"],
            "num_steps": trajectory["num_steps"],
            "quality_score": trajectory.get("quality_score", 1.0)
        }
    }
```

---

## 8. 数据构造最佳实践

### 8.1 方法选择建议

| 场景 | 推荐方法 | 理由 |
|------|----------|------|
| 快速启动 | E2HQA | 实现简单，可从现有数据快速生成 |
| 高复杂度需求 | SailorFog-QA V2 | 密集图谱结构，高推理深度 |
| 精确控制复杂度 | WebShaper | 形式化定义，完全可控 |
| 多领域覆盖 | WebFrontier | 多源语料，自动扩展 |
| 综合使用 | 混合策略 | 结合各方法优势 |

### 8.2 数据规模建议

| 训练阶段 | QA数据量 | 轨迹数据量 | 说明 |
|----------|----------|------------|------|
| SFT冷启动 | 5K-10K | 2K-5K | 高质量过滤后 |
| RL训练 | 10K-50K | 动态采样 | 用于奖励计算 |
| 持续优化 | 持续生成 | 持续采样 | 数据-策略共生 |

### 8.3 质量控制检查清单

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    数据质量检查清单                                              │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  QA数据检查:                                                                     │
│  □ 问题是否清晰、无歧义？                                                        │
│  □ 答案是否唯一确定？                                                            │
│  □ 答案是否可通过网络搜索验证？                                                  │
│  □ 问题复杂度是否达到要求（步数、跳数）？                                        │
│  □ 问题是否与已有数据足够不同？                                                  │
│  □ 问题是否覆盖目标领域？                                                        │
│                                                                                 │
│  轨迹数据检查:                                                                   │
│  □ 格式是否正确（标签闭合、JSON有效）？                                          │
│  □ 最终答案是否正确？                                                            │
│  □ 推理过程是否连贯？                                                            │
│  □ 是否存在幻觉（编造observation）？                                             │
│  □ 工具调用是否合理必要？                                                        │
│  □ 是否存在严重重复？                                                            │
│  □ 总长度是否在限制内？                                                          │
│                                                                                 │
│  数据集检查:                                                                     │
│  □ 领域分布是否均衡？                                                            │
│  □ 难度分布是否合理？                                                            │
│  □ 是否有训练/测试泄露风险？                                                     │
│  □ 数据量是否足够？                                                              │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 9. 总结

本模块详细介绍了Deep Research Agent的数据构造方法：

### 关键要点

1. **数据质量决定模型性能**：高质量、多样化的数据是成功的基础
2. **四种QA生成方法各有优势**：
   - SailorFog-QA：适合高复杂度、深度推理
   - WebFrontier：适合迭代式复杂度升级
   - WebShaper：适合精确控制推理结构
   - E2HQA：适合快速生成
3. **轨迹采样需要严格过滤**：三阶段漏斗确保质量
4. **持续迭代优化**：数据-策略共生循环

在下一模块中，我们将详细介绍如何使用这些数据进行模型训练。
