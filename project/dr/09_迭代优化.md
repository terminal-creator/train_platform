# 模块九：迭代优化

> 评估驱动的问题诊断、根因分析与系统性改进方法论

---

## 1. 概述

### 1.1 为什么需要系统性的迭代方法论？

构建 Deep Research Agent 不是一次性工程，而是持续优化的过程。评估只是发现问题的手段，真正的挑战在于：

- **如何从评估结果中定位具体问题？**
- **如何判断问题出在哪个环节？**
- **如何确定改进的优先级？**
- **如何验证改进是否有效？**

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        迭代优化的核心挑战                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  现象: 评估得分从 65% 下降到 60%                                                 │
│                                                                                 │
│  可能原因（至少10种）:                                                           │
│  ├─ 数据层: 新数据引入噪声、数据分布偏移、标注质量下降                           │
│  ├─ 模型层: 过拟合、灾难性遗忘、梯度问题                                        │
│  ├─ 工具层: API变更、解析器失效、超时增加                                       │
│  ├─ 框架层: Prompt变更引入bug、上下文管理问题                                   │
│  ├─ 评估层: 评估集污染、评估脚本bug、Judge模型波动                              │
│  └─ 环境层: 搜索引擎结果变化、目标网页内容更新                                   │
│                                                                                 │
│  没有系统性方法 → 盲目尝试 → 浪费时间 → 可能引入新问题                           │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 1.2 迭代优化的基本原则

| 原则 | 说明 | 反模式 |
|------|------|--------|
| **数据驱动** | 基于量化分析做决策，不凭直觉 | "我觉得是XX问题" |
| **单一变量** | 每次只改一个因素，便于归因 | 同时改数据+模型+Prompt |
| **可复现** | 保证实验可重复，结果可验证 | 没有版本控制和日志 |
| **防止回归** | 改进A不应导致B退化 | 只看目标指标，忽略其他 |
| **闭环验证** | 改进后必须重新评估确认 | 改完就上线，不验证 |

---

## 2. 问题诊断框架

### 2.1 错误分类体系

Deep Research Agent 的错误可以按发生阶段分为六大类：

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        错误分类体系                                              │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  用户问题                                                                        │
│      │                                                                          │
│      ▼                                                                          │
│  ┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐  │
│  │ 规划层  │ ──► │ 检索层  │ ──► │ 理解层  │ ──► │ 推理层  │ ──► │ 生成层  │  │
│  │         │     │         │     │         │     │         │     │         │  │
│  │ 分解问题│     │ 搜索执行│     │ 内容提取│     │ 信息整合│     │ 答案输出│  │
│  │ 制定策略│     │ 网页访问│     │ 关键信息│     │ 逻辑推理│     │ 格式化  │  │
│  └─────────┘     └─────────┘     └─────────┘     └─────────┘     └─────────┘  │
│       │               │               │               │               │        │
│       ▼               ▼               ▼               ▼               ▼        │
│  ┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐  │
│  │ E1类    │     │ E2类    │     │ E3类    │     │ E4类    │     │ E5类    │  │
│  │ 规划错误│     │ 检索错误│     │ 理解错误│     │ 推理错误│     │ 生成错误│  │
│  └─────────┘     └─────────┘     └─────────┘     └─────────┘     └─────────┘  │
│                                                                                 │
│  另有 E6类: 策略错误 (贯穿全流程的决策问题，如过早终止、过度搜索)                 │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 各类错误的详细特征

#### E1: 规划层错误

**定义**：问题分解或搜索策略制定阶段的错误

| 子类型 | 典型表现 | 示例 |
|--------|----------|------|
| **问题误解** | 理解的问题与用户意图不符 | 用户问"苹果股价"，系统理解为"苹果营养价值" |
| **分解不当** | 子问题遗漏关键方面或过度分解 | 比较A和B，只搜索了A的信息 |
| **策略偏离** | 搜索方向与问题无关 | 问技术问题，搜索了一堆新闻八卦 |
| **关键词质量差** | 搜索词过于宽泛或过于狭窄 | 搜索"东西"而非"锂电池正极材料" |

**诊断方法**：
```python
# 规划层错误诊断
def diagnose_planning_error(trajectory):
    issues = []

    # 1. 检查问题理解
    if not is_question_understood(trajectory.parsed_question, trajectory.original_question):
        issues.append("问题误解")

    # 2. 检查子问题覆盖度
    expected_aspects = extract_aspects(trajectory.original_question)
    covered_aspects = extract_aspects_from_queries(trajectory.search_queries)
    missing = expected_aspects - covered_aspects
    if missing:
        issues.append(f"子问题遗漏: {missing}")

    # 3. 检查搜索词质量
    for query in trajectory.search_queries:
        relevance = compute_query_relevance(query, trajectory.original_question)
        if relevance < 0.5:
            issues.append(f"低相关搜索词: {query}")

    return issues
```

#### E2: 检索层错误

**定义**：搜索执行和网页访问阶段的错误

| 子类型 | 典型表现 | 示例 |
|--------|----------|------|
| **工具调用格式错误** | JSON格式错误、参数缺失 | `{"query": }` 缺少值 |
| **API失败** | 超时、限流、服务不可用 | 搜索API返回500错误 |
| **网页访问失败** | 页面不存在、需要登录、反爬 | 403 Forbidden |
| **解析失败** | 网页结构变化导致解析器失效 | 提取到空内容 |

**诊断方法**：
```python
# 检索层错误诊断
def diagnose_retrieval_error(trajectory):
    issues = []

    for action in trajectory.actions:
        if action.type == "search":
            # 检查格式
            if not is_valid_json(action.raw_output):
                issues.append(f"工具调用格式错误: {action.raw_output[:100]}")

            # 检查API响应
            if action.response.status_code != 200:
                issues.append(f"API错误: {action.response.status_code}")

            # 检查结果质量
            if len(action.response.results) == 0:
                issues.append(f"搜索无结果: {action.query}")

        elif action.type == "visit":
            if action.response.content_length < 100:
                issues.append(f"网页内容过少: {action.url}")

    return issues
```

#### E3: 理解层错误

**定义**：从检索内容中提取信息时的错误

| 子类型 | 典型表现 | 示例 |
|--------|----------|------|
| **关键信息遗漏** | 答案在网页中但未被提取 | 数字、日期、名称未提取 |
| **信息误读** | 提取的信息与原文不符 | 原文说"增长10%"，提取为"下降10%" |
| **噪声干扰** | 提取了不相关的信息 | 提取了广告内容而非正文 |
| **上下文丢失** | 信息脱离上下文产生歧义 | "他"指代不明 |

**诊断方法**：
```python
# 理解层错误诊断
def diagnose_understanding_error(trajectory, ground_truth):
    issues = []

    for visit_action in trajectory.get_actions("visit"):
        page_content = visit_action.response.content
        extracted_info = visit_action.extracted_info

        # 检查是否遗漏关键信息
        key_facts = extract_key_facts(page_content, trajectory.question)
        for fact in key_facts:
            if fact in ground_truth.evidence and fact not in extracted_info:
                issues.append(f"关键信息遗漏: {fact}")

        # 检查是否有误读
        for info in extracted_info:
            if not verify_against_source(info, page_content):
                issues.append(f"信息误读: {info}")

    return issues
```

#### E4: 推理层错误

**定义**：信息整合和逻辑推理阶段的错误

| 子类型 | 典型表现 | 示例 |
|--------|----------|------|
| **多跳推理断裂** | 无法完成A→B→C的推理链 | 知道A是B的父亲，B是C的父亲，但无法推出A是C的祖父 |
| **矛盾信息处理不当** | 面对冲突信息时选择错误 | 两个来源数据不同，选了错误的那个 |
| **数值计算错误** | 加减乘除或单位换算错误 | 100万+200万=200万 |
| **逻辑谬误** | 因果倒置、过度泛化等 | 因为A和B同时发生，所以A导致B |

**诊断方法**：
```python
# 推理层错误诊断
def diagnose_reasoning_error(trajectory, ground_truth):
    issues = []

    # 1. 检查推理链完整性
    reasoning_chain = extract_reasoning_chain(trajectory)
    for i, (premise, conclusion) in enumerate(reasoning_chain):
        if not is_valid_inference(premise, conclusion):
            issues.append(f"推理链断裂@step{i}: {premise} -/-> {conclusion}")

    # 2. 检查数值计算
    calculations = extract_calculations(trajectory)
    for calc in calculations:
        if not verify_calculation(calc):
            issues.append(f"计算错误: {calc}")

    # 3. 检查矛盾处理
    conflicting_info = find_conflicts(trajectory.collected_info)
    if conflicting_info:
        resolution = trajectory.conflict_resolution
        if resolution != ground_truth.correct_resolution:
            issues.append(f"矛盾处理不当: 选择了{resolution}而非{ground_truth.correct_resolution}")

    return issues
```

#### E5: 生成层错误

**定义**：最终答案生成阶段的错误

| 子类型 | 典型表现 | 示例 |
|--------|----------|------|
| **格式错误** | 答案格式不符合要求 | 要求JSON但输出了纯文本 |
| **信息丢失** | 推理正确但答案遗漏信息 | 问3个人名只答了2个 |
| **幻觉生成** | 答案包含未检索到的信息 | 编造了一个不存在的引用 |
| **表述歧义** | 答案表述不清导致误解 | "大约100"实际是98还是102 |

#### E6: 策略层错误

**定义**：贯穿全流程的决策问题

| 子类型 | 典型表现 | 示例 |
|--------|----------|------|
| **过早终止** | 信息不足时就停止搜索 | 只搜索1次就给出答案 |
| **过度搜索** | 信息已足够但仍继续 | 搜索了50次重复信息 |
| **策略僵化** | 不根据反馈调整策略 | 同一个无效query重复搜索 |
| **资源浪费** | 访问大量无关页面 | 访问了100个页面但只有5个有用 |

### 2.3 错误诊断的标准流程

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        错误诊断标准流程                                          │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  Step 1: 收集错误样本                                                            │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  - 从评估结果中筛选错误case                                               │   │
│  │  - 保存完整的轨迹日志（包括所有中间步骤）                                  │   │
│  │  - 记录ground truth和模型输出的差异                                       │   │
│  │  - 按问题类型/难度分层抽样（确保代表性）                                   │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                      │                                          │
│                                      ▼                                          │
│  Step 2: 人工标注错误类型                                                        │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  - 2-3人独立标注，计算一致性                                              │   │
│  │  - 标注主要错误类型（E1-E6）和子类型                                       │   │
│  │  - 标注错误发生的具体步骤                                                 │   │
│  │  - 允许多标签（一个case可能有多个错误）                                    │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                      │                                          │
│                                      ▼                                          │
│  Step 3: 统计错误分布                                                            │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  - 计算各类错误的占比                                                     │   │
│  │  - 分析错误与问题特征的相关性                                             │   │
│  │  - 识别系统性失败模式                                                     │   │
│  │  - 输出诊断报告                                                           │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                      │                                          │
│                                      ▼                                          │
│  Step 4: 根因归因                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐   │
│  │  错误类型          │  可能根因                                            │   │
│  │  ─────────────────┼───────────────────────────────────────────────────   │   │
│  │  E1 规划错误       │  SFT数据缺乏规划示范 / 基座模型能力不足               │   │
│  │  E2 检索错误       │  工具定义不清晰 / 格式SFT数据不足                     │   │
│  │  E3 理解错误       │  网页解析模块问题 / 阅读理解能力不足                  │   │
│  │  E4 推理错误       │  多跳推理数据不足 / 需要RL强化                        │   │
│  │  E5 生成错误       │  答案格式SFT不足 / Prompt约束不够                     │   │
│  │  E6 策略错误       │  奖励函数设计问题 / RL训练不足                        │   │
│  └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 根因分析方法

### 3.1 数据层问题诊断

当怀疑问题出在训练数据时：

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        数据层问题诊断清单                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  □ 数据覆盖度检查                                                                │
│    - 失败case的问题类型在训练数据中是否有足够覆盖？                               │
│    - 失败case的推理深度在训练数据中是否有对应难度？                               │
│    - 失败case涉及的领域在训练数据中是否有覆盖？                                   │
│                                                                                 │
│  □ 数据质量检查                                                                  │
│    - 随机抽样检查训练数据的标注正确性                                            │
│    - 检查轨迹数据的工具调用格式是否规范                                           │
│    - 检查是否有明显的噪声或错误模式                                              │
│                                                                                 │
│  □ 数据分布检查                                                                  │
│    - 训练/测试数据分布是否一致？                                                 │
│    - 是否存在数据泄露？                                                          │
│    - 难度分布是否合理？                                                          │
│                                                                                 │
│  □ 数据时效性检查                                                                │
│    - 训练数据中的事实是否已过时？                                                │
│    - 网页内容是否已变化？                                                        │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

**数据问题的典型信号**：
- 特定类型问题系统性失败
- 模型"从未见过"某种模式
- 格式错误高度一致（说明SFT数据有格式问题）

### 3.2 模型层问题诊断

当怀疑问题出在模型本身时：

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        模型层问题诊断清单                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  □ 过拟合检查                                                                    │
│    - 训练集性能 vs 测试集性能差距                                                │
│    - 是否在训练后期性能开始下降                                                  │
│    - 换一批测试数据是否性能骤降                                                  │
│                                                                                 │
│  □ 灾难性遗忘检查                                                                │
│    - 基座模型原有能力是否保留（如基础问答、代码生成）                             │
│    - 不同能力维度的性能变化趋势                                                  │
│    - 是否某些能力显著退化                                                        │
│                                                                                 │
│  □ 能力天花板检查                                                                │
│    - 使用更强的基座模型是否能解决问题                                            │
│    - 人工提供正确信息后模型能否正确推理                                          │
│    - 问题是否超出模型参数量的能力范围                                            │
│                                                                                 │
│  □ 训练稳定性检查                                                                │
│    - Loss曲线是否正常收敛                                                        │
│    - 梯度是否有异常（爆炸/消失）                                                 │
│    - 不同随机种子结果是否一致                                                    │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

**模型问题的典型信号**：
- 训练集表现好但测试集差（过拟合）
- 之前能做对的现在做错了（遗忘）
- Loss下降但性能不涨（优化目标问题）

### 3.3 工具层问题诊断

当怀疑问题出在工具实现时：

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        工具层问题诊断清单                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  □ 工具可用性检查                                                                │
│    - 各工具API的成功率和延迟监控                                                 │
│    - 是否有限流、封禁、服务降级                                                  │
│    - 重试机制是否正常工作                                                        │
│                                                                                 │
│  □ 工具输出质量检查                                                              │
│    - 搜索结果的相关性是否下降                                                    │
│    - 网页解析是否完整提取内容                                                    │
│    - 是否有新的网页结构导致解析失败                                              │
│                                                                                 │
│  □ 工具定义清晰度检查                                                            │
│    - 工具描述是否准确反映功能                                                    │
│    - 参数说明是否清晰无歧义                                                      │
│    - 返回格式是否稳定一致                                                        │
│                                                                                 │
│  □ 工具调用日志分析                                                              │
│    - 统计各类工具调用失败的原因分布                                              │
│    - 分析失败case中工具调用的模式                                                │
│    - 对比成功/失败case的工具使用差异                                             │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

**工具问题的典型信号**：
- 工具调用成功率突然下降
- 特定网站的内容无法正确解析
- 模型正确调用工具但得到错误结果

### 3.4 框架层问题诊断

当怀疑问题出在Agent框架设计时：

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        框架层问题诊断清单                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  □ 上下文管理检查                                                                │
│    - 是否出现上下文截断导致信息丢失                                              │
│    - 历史信息的压缩/摘要是否有损关键内容                                         │
│    - 长轨迹任务的性能衰减曲线                                                    │
│                                                                                 │
│  □ Prompt模板检查                                                                │
│    - 最近是否有Prompt变更                                                        │
│    - Prompt是否有歧义或误导                                                      │
│    - 不同任务类型是否需要不同Prompt                                              │
│                                                                                 │
│  □ 终止条件检查                                                                  │
│    - 终止判断逻辑是否合理                                                        │
│    - 是否有max_steps等硬限制导致提前终止                                         │
│    - 超时设置是否合理                                                            │
│                                                                                 │
│  □ 错误处理检查                                                                  │
│    - 工具失败后的降级策略是否有效                                                │
│    - 异常是否被正确捕获和处理                                                    │
│    - 重试逻辑是否正常                                                            │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 针对性迭代策略

### 4.1 问题-方案映射表

| 诊断结果 | 根因 | 迭代方案 | 预期效果 | 验证方法 |
|----------|------|----------|----------|----------|
| E1规划错误占比高 | SFT数据缺乏规划示范 | 补充包含详细规划步骤的SFT数据 | 规划错误率下降50%+ | 人工评估规划质量 |
| E2工具格式错误多 | 格式SFT不足 | 增加工具调用格式的SFT数据 | 格式错误率<5% | 自动化格式检查 |
| E3信息遗漏严重 | 网页解析问题 | 优化解析器 / 使用更强的摘要模型 | 关键信息召回率提升 | 对比原文和提取结果 |
| E4多跳推理失败 | 推理能力不足 | 增加多跳推理数据 + RL强化 | 多跳题准确率提升 | 按推理深度分层评估 |
| E5答案格式错误 | 生成约束不足 | Prompt增加格式约束 / 后处理 | 格式正确率>95% | 自动化格式验证 |
| E6过早终止 | 奖励函数问题 | 调整奖励函数，增加覆盖度奖励 | 平均搜索轮数增加 | 统计轮数分布 |
| E6过度搜索 | 缺乏效率约束 | 增加效率惩罚 / 设置合理上限 | 平均耗时下降 | 统计耗时分布 |

### 4.2 数据迭代策略

#### 策略1: 针对性数据补充

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        针对性数据补充流程                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  1. 识别薄弱环节                                                                 │
│     ├─ 从错误分析中找出高频错误模式                                              │
│     ├─ 确定这些错误对应的能力缺口                                                │
│     └─ 量化：需要补充多少数据？什么类型？                                        │
│                                                                                 │
│  2. 数据生成/收集                                                                │
│     ├─ 方案A: 使用强模型生成目标类型的轨迹                                       │
│     ├─ 方案B: 从失败case出发，人工修正为正确轨迹                                 │
│     ├─ 方案C: 使用数据合成方法生成相似问题                                       │
│     └─ 注意: 保持数据多样性，避免过于相似                                        │
│                                                                                 │
│  3. 质量控制                                                                     │
│     ├─ 人工审核抽样检查                                                          │
│     ├─ 自动化规则过滤明显错误                                                    │
│     └─ 使用强模型进行质量打分                                                    │
│                                                                                 │
│  4. 混合训练                                                                     │
│     ├─ 将新数据与原有数据混合                                                    │
│     ├─ 控制新数据占比（通常10-30%）                                              │
│     └─ 监控是否引入新的问题                                                      │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

#### 策略2: 难度课程学习

```python
# 难度课程学习策略
class CurriculumDataMixer:
    def __init__(self, difficulty_levels=["easy", "medium", "hard", "expert"]):
        self.levels = difficulty_levels
        self.current_stage = 0
        self.stage_ratios = [
            {"easy": 0.7, "medium": 0.2, "hard": 0.1, "expert": 0.0},  # Stage 1
            {"easy": 0.4, "medium": 0.4, "hard": 0.15, "expert": 0.05}, # Stage 2
            {"easy": 0.2, "medium": 0.3, "hard": 0.35, "expert": 0.15}, # Stage 3
            {"easy": 0.1, "medium": 0.2, "hard": 0.4, "expert": 0.3},  # Stage 4
        ]

    def should_advance_stage(self, metrics):
        """根据当前阶段的性能决定是否进入下一阶段"""
        current_level = self.levels[min(self.current_stage, len(self.levels)-1)]
        threshold = {"easy": 0.9, "medium": 0.8, "hard": 0.7, "expert": 0.6}

        if metrics.get(f"{current_level}_accuracy", 0) > threshold[current_level]:
            return True
        return False

    def get_batch(self, all_data, batch_size):
        """按当前阶段的比例采样数据"""
        ratios = self.stage_ratios[self.current_stage]
        batch = []
        for level, ratio in ratios.items():
            n = int(batch_size * ratio)
            batch.extend(random.sample(all_data[level], min(n, len(all_data[level]))))
        return batch
```

### 4.3 模型迭代策略

#### 策略1: SFT迭代

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        SFT迭代决策树                                             │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  问题: 模型某项能力不足                                                          │
│           │                                                                     │
│           ▼                                                                     │
│  ┌─────────────────────────────────────┐                                       │
│  │ 该能力在SFT数据中有足够覆盖吗？      │                                       │
│  └─────────────────────────────────────┘                                       │
│           │                                                                     │
│     ┌─────┴─────┐                                                              │
│     ▼           ▼                                                              │
│    No          Yes                                                              │
│     │           │                                                              │
│     ▼           ▼                                                              │
│  补充数据    ┌─────────────────────────────────────┐                           │
│  重新SFT    │ SFT数据质量足够高吗？                │                           │
│             └─────────────────────────────────────┘                           │
│                       │                                                        │
│                 ┌─────┴─────┐                                                  │
│                 ▼           ▼                                                  │
│                No          Yes                                                  │
│                 │           │                                                  │
│                 ▼           ▼                                                  │
│             提升质量    ┌─────────────────────────────────────┐               │
│             重新SFT    │ 基座模型有这个能力吗？              │               │
│                        └─────────────────────────────────────┘               │
│                                   │                                           │
│                             ┌─────┴─────┐                                     │
│                             ▼           ▼                                     │
│                            No          Yes                                     │
│                             │           │                                     │
│                             ▼           ▼                                     │
│                        换更强基座    考虑RL强化                                │
│                        或接受局限    或调整学习率                              │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

#### 策略2: RL迭代

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        RL迭代调优指南                                            │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  常见问题及解决方案:                                                             │
│                                                                                 │
│  1. 奖励hacking（模型找到捷径获得高奖励但实际效果差）                             │
│     症状: RL指标上涨但真实评估下降                                               │
│     方案: 增加奖励多样性，添加格式/过程奖励，使用对抗样本                         │
│                                                                                 │
│  2. 策略崩溃（模型输出变得单一或退化）                                           │
│     症状: 输出多样性骤降，重复输出固定模式                                       │
│     方案: 增大KL惩罚系数，降低学习率，添加熵正则                                 │
│                                                                                 │
│  3. 训练不稳定（Loss/Reward剧烈波动）                                           │
│     症状: 指标曲线震荡不收敛                                                     │
│     方案: 减小学习率，增大batch size，使用梯度裁剪                               │
│                                                                                 │
│  4. 探索不足（模型不尝试新策略）                                                 │
│     症状: 策略与SFT后几乎相同                                                    │
│     方案: 增加探索温度，使用更激进的采样策略                                     │
│                                                                                 │
│  5. 泛化差（训练集好测试集差）                                                   │
│     症状: 训练/测试性能差距大                                                    │
│     方案: 增加训练问题多样性，使用数据增强，提前停止                             │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 4.4 工具与框架迭代策略

| 问题类型 | 迭代方案 | 实施要点 |
|----------|----------|----------|
| 搜索结果质量差 | 优化query改写 / 换搜索引擎 | 保持API兼容，A/B测试 |
| 网页解析失败率高 | 升级解析器 / 增加fallback | 针对Top失败域名专项优化 |
| 工具调用延迟高 | 增加缓存 / 并行调用 | 监控缓存命中率 |
| 上下文溢出 | 优化压缩策略 / 换更长上下文模型 | 确保不丢失关键信息 |
| 终止判断不准 | 调整阈值 / 增加判断逻辑 | 平衡准确率和召回率 |

---

## 5. 迭代优先级决策

### 5.1 优先级矩阵

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        迭代优先级矩阵                                            │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│                              影响范围                                            │
│                    小 ◄─────────────────────────────────► 大                    │
│                    │                                       │                    │
│         ┌──────────┼───────────────────────────────────────┼──────────┐        │
│         │          │                                       │          │        │
│         │   P3     │              P2                       │    P1    │  难    │
│  修     │ 长期规划 │         重要但困难                     │  战略级  │  ▲    │
│  复     │          │         需要专项攻关                   │  优先级  │  │    │
│  难     ├──────────┼───────────────────────────────────────┼──────────┤  │    │
│  度     │          │                                       │          │  │    │
│         │   P4     │              P3                       │    P2    │  │    │
│         │ 可延后   │           正常迭代                     │ 高ROI   │  易    │
│         │          │                                       │          │        │
│         └──────────┴───────────────────────────────────────┴──────────┘        │
│                                                                                 │
│  P1 (立即处理): 影响范围大 + 有可行方案                                          │
│      例: 工具调用格式错误率30%，补充SFT数据可解决                                │
│                                                                                 │
│  P2 (高优先级): 影响范围大但困难 或 影响中等但容易                               │
│      例: 多跳推理能力不足(大+难) 或 某类问题格式错误(中+易)                      │
│                                                                                 │
│  P3 (正常迭代): 影响中等，按正常节奏处理                                         │
│      例: 特定领域(如医学)表现弱，可以专项优化但不紧急                            │
│                                                                                 │
│  P4 (可延后): 影响小，资源允许时处理                                             │
│      例: 极端边缘case，发生频率<1%                                               │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 5.2 决策检查清单

在决定迭代优先级时，回答以下问题：

```
□ 这个问题影响多少比例的用户/请求？
  - >10% → 高影响
  - 1-10% → 中影响
  - <1% → 低影响

□ 这个问题的严重程度？
  - 完全失败/崩溃 → 严重
  - 结果错误但系统正常 → 中等
  - 体验不佳但可用 → 轻微

□ 修复的难度和成本？
  - 改配置/Prompt → 低成本
  - 补充数据重训 → 中成本
  - 架构调整/换模型 → 高成本

□ 是否有快速的临时方案？
  - 有 → 可以先上临时方案，再彻底修复
  - 无 → 需要直接解决

□ 修复后是否可能引入新问题？
  - 高风险 → 需要充分测试
  - 低风险 → 可以快速迭代
```

---

## 6. 验证与回归测试

### 6.1 验证流程

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        改进验证流程                                              │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  ┌─────────────┐                                                                │
│  │  单元验证   │  针对具体修复的问题进行验证                                     │
│  │             │  - 原来失败的case现在是否成功                                  │
│  │             │  - 同类问题的成功率是否提升                                    │
│  └──────┬──────┘                                                                │
│         │ 通过                                                                   │
│         ▼                                                                       │
│  ┌─────────────┐                                                                │
│  │  回归测试   │  确保没有引入新问题                                             │
│  │             │  - 在完整评估集上测试                                          │
│  │             │  - 重点关注相关模块的指标                                      │
│  │             │  - 对比改进前后的全面指标                                      │
│  └──────┬──────┘                                                                │
│         │ 通过                                                                   │
│         ▼                                                                       │
│  ┌─────────────┐                                                                │
│  │  灰度验证   │  小流量线上验证                                                 │
│  │             │  - 1-5%流量切到新版本                                          │
│  │             │  - 监控线上指标                                                │
│  │             │  - 收集用户反馈                                                │
│  └──────┬──────┘                                                                │
│         │ 通过                                                                   │
│         ▼                                                                       │
│  ┌─────────────┐                                                                │
│  │  全量发布   │  确认无问题后全量                                               │
│  │             │  - 保留回滚能力                                                │
│  │             │  - 持续监控                                                    │
│  └─────────────┘                                                                │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 6.2 回归测试设计

```python
class RegressionTestSuite:
    """回归测试套件"""

    def __init__(self):
        self.test_sets = {
            "core": self.load_core_tests(),        # 核心功能测试
            "edge_cases": self.load_edge_cases(),  # 边缘case
            "historical_bugs": self.load_bug_fixes(),  # 历史bug回归
            "performance": self.load_perf_tests(), # 性能测试
        }
        self.baseline_metrics = self.load_baseline()

    def run_regression(self, model, threshold=0.02):
        """运行回归测试，允许threshold的性能波动"""
        results = {}
        regressions = []

        for test_name, test_set in self.test_sets.items():
            metric = self.evaluate(model, test_set)
            baseline = self.baseline_metrics[test_name]

            results[test_name] = {
                "current": metric,
                "baseline": baseline,
                "delta": metric - baseline
            }

            # 检测回归
            if metric < baseline - threshold:
                regressions.append({
                    "test": test_name,
                    "regression": baseline - metric,
                    "severity": "high" if baseline - metric > 0.05 else "medium"
                })

        return {
            "passed": len(regressions) == 0,
            "results": results,
            "regressions": regressions
        }

    def update_baseline(self, new_metrics):
        """模型正式发布后更新baseline"""
        self.baseline_metrics = new_metrics
        self.save_baseline()
```

### 6.3 持续监控指标

| 指标类别 | 具体指标 | 监控频率 | 告警阈值 |
|----------|----------|----------|----------|
| **准确性** | 任务成功率 | 实时 | 下降>5% |
| **稳定性** | 工具调用成功率 | 实时 | <95% |
| **效率** | 平均响应时间 | 实时 | 上涨>50% |
| **资源** | 平均Token消耗 | 小时 | 上涨>30% |
| **质量** | 用户满意度评分 | 天 | 下降>0.5分 |

---

## 7. 迭代闭环最佳实践

### 7.1 完整闭环流程

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        持续迭代闭环                                              │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│         ┌──────────────────────────────────────────────────────────┐           │
│         │                                                          │           │
│         ▼                                                          │           │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   线上监控  │───►│   评估分析  │───►│   问题诊断  │───►│   方案制定  │     │
│  │             │    │             │    │             │    │             │     │
│  │ -实时指标   │    │ -定期评估   │    │ -错误分类   │    │ -优先级排序 │     │
│  │ -用户反馈   │    │ -深度分析   │    │ -根因归因   │    │ -资源评估   │     │
│  │ -异常告警   │    │ -趋势追踪   │    │ -影响评估   │    │ -方案设计   │     │
│  └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘     │
│                                                                   │             │
│         ┌─────────────────────────────────────────────────────────┘             │
│         │                                                                       │
│         ▼                                                                       │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   改进实施  │───►│   离线验证  │───►│   灰度发布  │───►│   全量发布  │──┐  │
│  │             │    │             │    │             │    │             │  │  │
│  │ -数据补充   │    │ -单元测试   │    │ -小流量     │    │ -全量切换   │  │  │
│  │ -模型训练   │    │ -回归测试   │    │ -监控对比   │    │ -持续监控   │  │  │
│  │ -工具优化   │    │ -A/B对比    │    │ -问题收集   │    │ -文档更新   │  │  │
│  └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘  │  │
│                                                                            │  │
│         ┌──────────────────────────────────────────────────────────────────┘  │
│         │                                                                      │
│         └──────────────────────────────────────────────────────────────────────┘
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 7.2 关键原则

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        迭代优化的关键原则                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  1. 保持评估集稳定性                                                             │
│     ├─ 核心评估集不要频繁变动                                                    │
│     ├─ 避免"刷榜"式优化（针对评估集过拟合）                                      │
│     ├─ 定期检查评估集是否被污染                                                  │
│     └─ 使用held-out测试集验证泛化能力                                            │
│                                                                                 │
│  2. 小步快跑                                                                     │
│     ├─ 每次迭代只改一个因素                                                      │
│     ├─ 频繁验证，快速反馈                                                        │
│     ├─ 避免大规模重构后才验证                                                    │
│     └─ 保持可回滚能力                                                            │
│                                                                                 │
│  3. 数据闭环                                                                     │
│     ├─ 线上badcase自动收集                                                       │
│     ├─ 定期将badcase转化为训练/测试数据                                          │
│     ├─ 追踪badcase修复率                                                         │
│     └─ 建立case管理系统                                                          │
│                                                                                 │
│  4. 全面监控                                                                     │
│     ├─ 不只看主指标，关注多维度                                                  │
│     ├─ 建立指标之间的关联分析                                                    │
│     ├─ 异常自动告警                                                              │
│     └─ 定期review监控仪表盘                                                      │
│                                                                                 │
│  5. 知识沉淀                                                                     │
│     ├─ 记录每次迭代的决策和结果                                                  │
│     ├─ 总结有效/无效的改进方法                                                   │
│     ├─ 建立问题-方案知识库                                                       │
│     └─ 团队定期复盘分享                                                          │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 7.3 常见反模式

| 反模式 | 问题 | 正确做法 |
|--------|------|----------|
| **盲目尝试** | 没有诊断就随便改，浪费时间 | 先诊断后行动 |
| **同时改多个** | 无法归因哪个改动有效 | 单一变量控制 |
| **只看主指标** | 忽视回归和副作用 | 全面评估 |
| **改完不验证** | 不知道是否真的改好了 | 必须验证 |
| **过度优化** | 针对评估集过拟合 | 保持评估集稳定 |
| **忽视长期** | 只修复眼前问题 | 兼顾短期和长期 |

---

## 8. 案例研究

### 8.1 案例：多跳推理能力提升

**问题发现**：
- 评估显示在需要3+跳推理的问题上准确率只有35%
- 而1-2跳问题准确率达到75%

**诊断过程**：
1. 抽样100个失败的多跳问题进行人工分析
2. 发现70%的错误发生在第2-3跳推理
3. 具体表现：模型能找到正确信息，但无法正确连接

**根因归因**：
- SFT数据中多跳推理的轨迹不足（只占5%）
- 多跳推理的示范质量参差不齐

**迭代方案**：
1. 使用GPT-4生成500条高质量多跳推理轨迹
2. 人工审核确保推理链完整性
3. 将多跳数据占比提升到20%
4. 重新进行SFT训练

**验证结果**：
- 多跳推理准确率从35%提升到58%
- 1-2跳问题准确率保持在74%（无回归）

### 8.2 案例：工具调用格式错误修复

**问题发现**：
- 线上监控发现工具调用失败率突然从5%上升到15%
- 主要是JSON格式解析错误

**诊断过程**：
1. 分析失败日志，发现模型输出的JSON经常缺少引号
2. 追溯发现是最近一次模型更新引入的问题
3. 对比新旧模型的输出分布

**根因归因**：
- 新加入的SFT数据中有部分格式不规范
- 这些数据污染了模型的格式输出能力

**迭代方案**：
1. 紧急方案：增加JSON后处理修复逻辑
2. 长期方案：清洗SFT数据，过滤格式错误样本
3. 增加格式验证的自动化检查

**验证结果**：
- 紧急方案上线后失败率降到8%
- 长期方案上线后失败率降到3%

---

## 9. 总结

### 9.1 核心要点回顾

1. **评估只是起点**：发现问题只是第一步，真正的价值在于诊断和改进
2. **系统性诊断**：使用错误分类体系，避免盲目尝试
3. **根因归因**：区分数据/模型/工具/框架层问题，对症下药
4. **优先级决策**：基于影响范围和修复难度做决策
5. **验证闭环**：改进后必须验证，防止回归
6. **持续迭代**：建立自动化的监控-诊断-改进-验证闭环

### 9.2 迭代优化检查清单

```
□ 是否有完整的错误日志和轨迹记录？
□ 是否对错误进行了系统性分类？
□ 是否找到了问题的根本原因？
□ 是否评估了改进方案的优先级？
□ 是否采用单一变量控制原则？
□ 是否进行了充分的回归测试？
□ 是否有灰度发布机制？
□ 是否更新了相关文档和知识库？
```

---

## 参考资料

- [Debugging Machine Learning Models](https://developers.google.com/machine-learning/testing-debugging)
- [A/B Testing for Machine Learning](https://netflixtechblog.com/experimentation-is-a-major-focus-of-data-science-across-netflix-f67f1f27b0c6)
- [Continuous Evaluation of ML Systems](https://research.google/pubs/pub46555/)
- [Error Analysis for NLP](https://aclanthology.org/2020.emnlp-main.489/)
