{
  "name": "GSPO - Group Self-Play Preference Optimization",
  "description": "组采样策略优化训练配置模板。结合自我博弈的偏好优化方法。",
  "category": "reinforcement_learning",
  "algorithm": "gspo",
  "verl_module": "verl.trainer.main_ppo",
  "verl_adv_estimator": "grpo",
  "required_fields": ["model_path", "train_data_path"],
  "data_format": {
    "type": "prompt-only",
    "required_columns": ["prompt"],
    "optional_columns": ["data_source", "solution"],
    "description": "每条数据包含prompt字段"
  },
  "defaults": {
    "num_epochs": 3,
    "learning_rate": 1e-6,
    "batch_size": 256,
    "micro_batch_size": 4,
    "max_prompt_length": 512,
    "max_response_length": 1024,
    "rollout_n": 8,
    "kl_coef": 0.001,
    "use_kl_loss": true,
    "lora_enabled": false
  },
  "parameter_ranges": {
    "learning_rate": {"min": 1e-8, "max": 1e-4, "recommended": 1e-6},
    "rollout_n": {"min": 2, "max": 32, "recommended": 8}
  },
  "tips": [
    "GSPO通过自我博弈的方式生成偏好数据",
    "较大的rollout_n有助于更好的对比采样"
  ]
}
