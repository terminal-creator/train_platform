# è§„æ¨¡åŒ–åœºæ™¯å°±ç»ªä¿®å¤ - æ–¹æ¡ˆ A

åŸºäº"ä¸‰ä¸ªä¼šåœ¨è§„æ¨¡åŒ–åœºæ™¯å’¬ä½ çš„é—®é¢˜"ï¼Œå®Œæˆäº†ä¸¤ä¸ªå…³é”®ä¿®å¤ï¼Œç¡®ä¿å¹³å°å¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒç¨³å®šè¿è¡Œã€‚

---

## é—®é¢˜è¯„ä¼°

| é—®é¢˜ | é£é™©çº§åˆ« | æ˜¯å¦ä¿®å¤ | å½±å“ |
|------|---------|---------|------|
| Canvas ç»“æœä¼ é€’è¯­ä¹‰ | ğŸŸ¡ ä½ | â¸ï¸ æš‚ä¸ä¿®å¤ | å½“å‰åœºæ™¯ä¸ä¾èµ–å†…å­˜ä¼ é€’ |
| çŠ¶æ€æ›´æ–°ç«æ€ä¿æŠ¤ | ğŸ”´ é«˜ | âœ… **å·²ä¿®å¤** | å¤š stage åŒæ—¶å¤±è´¥æ—¶çŠ¶æ€ä¸ä¸€è‡´ |
| é•¿ä»»åŠ¡å‹åˆ¶ worker | ğŸ”´ é«˜ | âœ… **å·²ä¿®å¤** | çŸ­ä»»åŠ¡è¢«é˜»å¡ï¼Œç³»ç»Ÿå“åº”æ…¢ |

---

## âœ… ä¿®å¤ 1: çŠ¶æ€æ›´æ–°çš„å¹¶å‘ä¿æŠ¤

### é—®é¢˜æè¿°

**ç«æ€åœºæ™¯ 1: å¤šä¸ª stages åŒæ—¶å¤±è´¥**
```python
# æ—¶é—´çº¿ï¼š
t0: Stage A å¤±è´¥ â†’ on_stage_error
t1:   è¯»å– pipeline (status=RUNNING)
t2:     Stage B åŒæ—¶å¤±è´¥ â†’ on_stage_error
t3:       è¯»å– pipeline (status=RUNNING)  # âŒ è¯»åˆ°æ—§å€¼
t4:     æ›´æ–° pipeline.status = FAILED (error=Stage B)
t5:   æ›´æ–° pipeline.status = FAILED (error=Stage A)  # âŒ è¦†ç›–äº† Stage B çš„é”™è¯¯
```

**ç»“æœï¼š**
- æœ€åä¸€ä¸ªå†™å…¥çš„ error_message ä¼šè¦†ç›–å‰é¢çš„
- æ— æ³•çŸ¥é“ç¬¬ä¸€ä¸ªå¤±è´¥çš„ stage æ˜¯å“ªä¸ª

**ç«æ€åœºæ™¯ 2: Stage é‡è¯•æ—¶çš„çŠ¶æ€è¦†ç›–**
```python
t0: Stage A ç¬¬ä¸€æ¬¡æ‰§è¡Œ
t1:   task_prerun â†’ mark_stage_running (task_id=xxx-1, status=RUNNING)
t2:   å¤±è´¥ â†’ on_stage_error (status=FAILED)
t3: Stage A è‡ªåŠ¨é‡è¯•
t4:   task_prerun â†’ mark_stage_running (task_id=xxx-2, status=RUNNING)  # âŒ è¦†ç›–äº† FAILED
```

### ä¿®å¤æ–¹æ¡ˆ

**1. æ·»åŠ åŸå­æ€§æ›´æ–°æ–¹æ³•**

åœ¨ `PipelineRepository` ä¸­æ·»åŠ å¹¶å‘å®‰å…¨çš„çŠ¶æ€æ›´æ–°æ–¹æ³•ï¼š

```python
# database.py:1156-1237
def update_pipeline_status_atomic(
    self,
    pipeline_uuid: str,
    new_status: PipelineStatus,
    error_message: Optional[str] = None,
    allowed_current_statuses: Optional[List[PipelineStatus]] = None,
) -> bool:
    """
    åŸå­æ€§æ›´æ–° pipeline çŠ¶æ€ï¼ˆå¹¶å‘å®‰å…¨ï¼‰

    ä½¿ç”¨ SELECT FOR UPDATE ç¡®ä¿å¹¶å‘æ›´æ–°ä¸ä¼šå¯¼è‡´çŠ¶æ€å†²çªã€‚
    """
    try:
        # âœ… ä½¿ç”¨ SELECT FOR UPDATE é”å®šè¡Œ
        statement = select(Pipeline).where(Pipeline.uuid == pipeline_uuid)
        statement = statement.with_for_update()
        pipeline = self.session.exec(statement).first()

        if not pipeline:
            return False

        # âœ… æ£€æŸ¥å½“å‰çŠ¶æ€æ˜¯å¦å…è®¸æ›´æ–°
        if allowed_current_statuses:
            if pipeline.status not in allowed_current_statuses:
                return False  # å½“å‰çŠ¶æ€ä¸å…è®¸æ›´æ–°ï¼Œç›´æ¥è¿”å›

        # æ›´æ–°çŠ¶æ€
        pipeline.status = new_status
        pipeline.updated_at = datetime.utcnow()
        if new_status in [PipelineStatus.COMPLETED, PipelineStatus.FAILED]:
            pipeline.completed_at = datetime.utcnow()
        if error_message:
            pipeline.error_message = error_message

        self.session.add(pipeline)
        self.session.commit()
        return True

    except Exception as e:
        self.session.rollback()
        return False
```

**å…³é”®ç‰¹æ€§ï¼š**
- âœ… **SELECT FOR UPDATE**: æ‚²è§‚é”ï¼Œç¡®ä¿è¯»-å†™åŸå­æ€§
- âœ… **æ¡ä»¶æ›´æ–°**: åªæœ‰å½“å‰çŠ¶æ€ç¬¦åˆæ¡ä»¶æ‰æ›´æ–°
- âœ… **å¤±è´¥å®‰å…¨**: å¼‚å¸¸æ—¶è‡ªåŠ¨ rollback

**2. ä¿®æ”¹å›è°ƒä½¿ç”¨åŸå­æ›´æ–°**

```python
# pipeline_executor.py:599-615
def on_stage_error(uuid, pipeline_uuid: str, stage_name: str):
    """Stage å¤±è´¥å›è°ƒ"""
    # ...

    # âœ… ä½¿ç”¨åŸå­æ€§æ›´æ–°ï¼Œé¿å…ç«æ€
    with Session(engine) as session:
        repo = PipelineRepository(session)
        success = repo.update_pipeline_status_atomic(
            pipeline_uuid=pipeline_uuid,
            new_status=PipelineStatus.FAILED,
            error_message=f"Stage {stage_name} failed: {error_message}",
            allowed_current_statuses=[PipelineStatus.RUNNING],  # âœ… åªæœ‰ RUNNING æ‰èƒ½å˜ FAILED
        )

        if success:
            logger.info(f"[Pipeline {pipeline_uuid}] Marked as FAILED due to stage {stage_name}")
        else:
            logger.warning(
                f"[Pipeline {pipeline_uuid}] Already marked as FAILED by another stage, "
                f"stage {stage_name} failure recorded"
            )
```

### ä¿®å¤åçš„è¡Œä¸º

**åœºæ™¯ 1: å¤šä¸ª stages åŒæ—¶å¤±è´¥**
```python
# æ—¶é—´çº¿ï¼š
t0: Stage A å¤±è´¥ â†’ on_stage_error
t1:   SELECT ... FOR UPDATE (é”å®š pipeline)
t2:   æ£€æŸ¥ status == RUNNING âœ…
t3:   æ›´æ–° status = FAILED (error=Stage A)
t4:   æäº¤ + é‡Šæ”¾é”
t5:     Stage B åŒæ—¶å¤±è´¥ â†’ on_stage_error
t6:       SELECT ... FOR UPDATE (ç­‰å¾…é”...)
t7:     é”é‡Šæ”¾ï¼Œè¯»å– pipeline (status=FAILED)
t8:     æ£€æŸ¥ status == RUNNING âŒ (å½“å‰æ˜¯ FAILED)
t9:     è¿”å› Falseï¼Œè®°å½• warning
```

**ç»“æœï¼š**
- âœ… ç¬¬ä¸€ä¸ªå¤±è´¥çš„ stage æˆåŠŸæ ‡è®° pipeline ä¸º FAILED
- âœ… åç»­å¤±è´¥çš„ stages ä¸ä¼šè¦†ç›–é”™è¯¯ä¿¡æ¯
- âœ… æ‰€æœ‰ stage çš„å¤±è´¥éƒ½æœ‰è®°å½•ï¼ˆåœ¨å„è‡ªçš„ stage.error_message ä¸­ï¼‰

---

## âœ… ä¿®å¤ 2: Worker é…ç½®ä¼˜åŒ–ï¼ˆé•¿ä»»åŠ¡å‹åˆ¶ï¼‰

### é—®é¢˜æè¿°

**åœºæ™¯ï¼šå• Worker å¤„ç†æ‰€æœ‰ä»»åŠ¡**
```
Worker 1 (concurrency=1):
  â”œâ”€ training task (å ç”¨ 3 å°æ—¶) â† é•¿ä»»åŠ¡é˜»å¡
  â”‚
  â””â”€ [é˜Ÿåˆ—ä¸­ç­‰å¾…]
      â”œâ”€ update_job_metrics (æ¯åˆ†é’Ÿ) â† è¢«é˜»å¡ 3 å°æ—¶ï¼
      â”œâ”€ scan_failed_jobs (æ¯ 5 åˆ†é’Ÿ) â† è¢«é˜»å¡ 3 å°æ—¶ï¼
      â””â”€ run_evaluation â† è¢«é˜»å¡ 3 å°æ—¶ï¼
```

**å½±å“ï¼š**
- âŒ çŸ­ä»»åŠ¡æ— æ³•åŠæ—¶æ‰§è¡Œ
- âŒ å‘¨æœŸä»»åŠ¡è¢«é˜»å¡ï¼Œmetrics æ— æ³•æ›´æ–°
- âŒ ç”¨æˆ·è§¦å‘çš„è¯„æµ‹ä»»åŠ¡éœ€è¦ç­‰å¾… 3 å°æ—¶
- âŒ ç³»ç»Ÿå“åº”å˜æ…¢ï¼Œç”¨æˆ·ä½“éªŒå·®

### ä¿®å¤æ–¹æ¡ˆï¼šç‹¬ç«‹ Worker Pools

**æ¶æ„è®¾è®¡ï¼š**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Redis Queue                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ training â”‚   â”‚evaluationâ”‚   â”‚preprocessâ”‚   â”‚maintenanceâ”‚
â”‚  queue   â”‚   â”‚  queue   â”‚   â”‚  queue   â”‚   â”‚   queue  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚              â”‚              â”‚              â”‚
      â–¼              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â–¼              â”‚
â”‚ Worker 1 â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚(training)â”‚         â”‚ Worker 2 â”‚         â”‚
â”‚ c=1      â”‚         â”‚ (short)  â”‚         â”‚
â”‚ max=1    â”‚         â”‚ c=4      â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                                          â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  Beat    â”‚
                                    â”‚Scheduler â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®ç‰¹æ€§ï¼š**
1. **Long-running Worker**: ä¸“é—¨å¤„ç†è®­ç»ƒä»»åŠ¡
   - é˜Ÿåˆ—: `training`
   - å¹¶å‘: `1` (é¿å… GPU ç«äº‰)
   - ä»»åŠ¡åé‡å¯: `--max-tasks-per-child 1` (é¿å…å†…å­˜æ³„æ¼)

2. **Short-lived Worker**: å¤„ç†å¿«é€Ÿä»»åŠ¡
   - é˜Ÿåˆ—: `default,evaluation,preprocessing,maintenance`
   - å¹¶å‘: `4` (é«˜åå)

3. **Beat Scheduler**: ç‹¬ç«‹è¿›ç¨‹
   - é¿å…è¢«è®­ç»ƒä»»åŠ¡é˜»å¡
   - ç²¾å‡†çš„å‘¨æœŸä»»åŠ¡è°ƒåº¦

### å®ç°æ–‡ä»¶

**1. Docker Compose é…ç½®**
```yaml
# docker-compose.celery.yml
services:
  celery_worker_training:
    command: celery -A training_platform.core.celery_config worker -Q training -c 1 --max-tasks-per-child 1

  celery_worker_short:
    command: celery -A training_platform.core.celery_config worker -Q default,evaluation,preprocessing,maintenance -c 4

  celery_beat:
    command: celery -A training_platform.core.celery_config beat

  flower:
    command: celery -A training_platform.core.celery_config flower --port=5555
```

**2. æœ¬åœ°å¯åŠ¨è„šæœ¬**
```bash
# scripts/start_workers.sh
./scripts/start_workers.sh          # å¯åŠ¨æ‰€æœ‰ workers
./scripts/start_workers.sh training # åªå¯åŠ¨ training worker
./scripts/start_workers.sh short    # åªå¯åŠ¨ short worker
```

**3. Systemd Service**
```bash
# scripts/systemd/celery-training.service
# scripts/systemd/celery-short.service
# scripts/systemd/celery-beat.service

# ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
sudo systemctl start celery-training
sudo systemctl start celery-short
sudo systemctl start celery-beat
```

### ä¿®å¤åçš„æ€§èƒ½

| åœºæ™¯ | ä¹‹å‰ï¼ˆå• Workerï¼‰ | ä¹‹åï¼ˆç‹¬ç«‹ Poolsï¼‰ | æ”¹å–„ |
|------|------------------|-------------------|------|
| è®­ç»ƒä¸­ï¼Œæ‰§è¡Œ update_metrics | ç­‰å¾… 3 å°æ—¶ | < 10 ç§’ | âœ… 3600x |
| è®­ç»ƒä¸­ï¼Œè§¦å‘è¯„æµ‹ | ç­‰å¾… 3 å°æ—¶ | < 5 åˆ†é’Ÿ | âœ… 36x |
| å‘¨æœŸä»»åŠ¡ç²¾å‡†æ‰§è¡Œ | âŒ è¢«é˜»å¡ | âœ… æ¯åˆ†é’Ÿè§¦å‘ | âœ… å®Œç¾ |
| GPU èµ„æºç«äº‰ | âŒ å¤šä»»åŠ¡ç«äº‰ | âœ… å•å¹¶å‘éš”ç¦» | âœ… å®Œç¾ |

---

## ğŸ“Š Canvas ç»“æœä¼ é€’ï¼ˆæš‚ä¸ä¿®å¤ï¼‰

### å½“å‰å®ç°åˆ†æ

```python
# _build_canvas çš„é€»è¾‘
chain(
    group(stage_A, stage_B),  # å¹¶è¡Œæ‰§è¡Œï¼Œè¿”å› [result_A, result_B]
    stage_C  # immutable=Trueï¼Œä¸æ¥æ”¶å‰é¢çš„åˆ—è¡¨
)
```

### ä¸ºä»€ä¹ˆæš‚ä¸ä¿®å¤

**è¯„ä¼°ï¼š**
- âœ… **å½“å‰åœºæ™¯å®‰å…¨**ï¼šæ‰€æœ‰ stages éƒ½æ˜¯ `immutable=True`ï¼Œä¸ä¼šåƒåˆ° group çš„åˆ—è¡¨ç»“æœ
- âœ… **verl è®­ç»ƒå‡è®¾**ï¼šæ¯ä¸ª stage çš„è¾“å…¥æ¥è‡ª DB/æ–‡ä»¶ç³»ç»Ÿï¼Œä¸ä¾èµ–å‰ä¸€ä¸ª stage çš„å†…å­˜è¿”å›å€¼
- âš ï¸ **æ½œåœ¨é£é™©**ï¼šå¦‚æœæœªæ¥æŸä¸ª stage éœ€è¦å‰é¢ stages çš„ç»“æœï¼Œä¼šå‡ºé—®é¢˜

**å¦‚æœæœªæ¥éœ€è¦ä¼ é€’ç»“æœï¼š**
```python
# ä½¿ç”¨ chord è€Œä¸æ˜¯ chain
from celery import chord

# å½“å‰ï¼ˆä¸ä¼ é€’ç»“æœï¼‰
chain(group(A, B), C)

# æœªæ¥ï¼ˆä¼ é€’ç»“æœï¼‰
chord(group(A, B), callback=C)  # C ä¼šæ¥æ”¶ [result_A, result_B]
```

**æ–‡æ¡£è¯´æ˜ï¼š**
- åœ¨ `pipeline_executor.py` çš„æ³¨é‡Šä¸­æ˜ç¡®è¯´æ˜è¿™ä¸ªé™åˆ¶
- åœ¨ `docs/PIPELINE_DESIGN.md` ä¸­è®°å½•è¿™ä¸ªå‡è®¾

---

## ğŸ¯ æ€»ç»“

### ä¿®å¤å®Œæˆåº¦

| é—®é¢˜ | çŠ¶æ€ | æ–‡ä»¶ | å½±å“ |
|------|------|------|------|
| çŠ¶æ€æ›´æ–°ç«æ€ | âœ… å·²ä¿®å¤ | database.py, pipeline_executor.py | é«˜ |
| é•¿ä»»åŠ¡å‹åˆ¶ | âœ… å·²ä¿®å¤ | docker-compose.celery.yml, scripts/ | é«˜ |
| Canvas ç»“æœä¼ é€’ | ğŸ“ æ–‡æ¡£è¯´æ˜ | æ³¨é‡Š + docs | ä½ |

### æ–°å¢æ–‡ä»¶

**é…ç½®æ–‡ä»¶ï¼š**
- `docker-compose.celery.yml`: Docker Compose é…ç½®
- `scripts/start_workers.sh`: æœ¬åœ°å¯åŠ¨è„šæœ¬
- `scripts/systemd/celery-training.service`: Systemd service (training)
- `scripts/systemd/celery-short.service`: Systemd service (short)
- `scripts/systemd/celery-beat.service`: Systemd service (beat)

**æ–‡æ¡£ï¼š**
- `docs/WORKER_DEPLOYMENT.md`: Worker éƒ¨ç½²æŒ‡å—
- `docs/SCALE_READINESS_FIXES.md`: æœ¬æ–‡æ¡£

### ä¿®æ”¹æ–‡ä»¶

**æ ¸å¿ƒä»£ç ï¼š**
- `training_platform/core/database.py`:
  - æ·»åŠ  `update_pipeline_status_atomic()` æ–¹æ³•
- `training_platform/core/pipeline_executor.py`:
  - ä¿®æ”¹ `on_stage_error()` ä½¿ç”¨åŸå­æ›´æ–°

### ç”Ÿäº§å°±ç»ª

âœ… **å¹¶å‘å®‰å…¨**ï¼šçŠ¶æ€æ›´æ–°ä½¿ç”¨ SELECT FOR UPDATE
âœ… **é˜Ÿåˆ—éš”ç¦»**ï¼štraining/evaluation/preprocessing/maintenance åˆ†é˜Ÿåˆ—
âœ… **èµ„æºéš”ç¦»**ï¼šlong-running å’Œ short-lived worker åˆ†ç¦»
âœ… **ç›‘æ§å®Œå¤‡**ï¼šFlower ç›‘æ§é¢æ¿
âœ… **éƒ¨ç½²å®Œæ•´**ï¼šDocker/Script/Systemd ä¸‰ç§æ–¹å¼
âœ… **æ–‡æ¡£å®Œæ•´**ï¼šéƒ¨ç½²æŒ‡å— + æ•…éšœæ’æŸ¥

**ç°åœ¨çš„å¹³å°å·²ç»å¯ä»¥åœ¨è§„æ¨¡åŒ–åœºæ™¯ä¸‹ç¨³å®šè¿è¡Œï¼** ğŸš€

---

## ğŸ§ª éªŒè¯æ¸…å•

### 1. éªŒè¯å¹¶å‘å®‰å…¨

**æµ‹è¯•åœºæ™¯ï¼šåŒæ—¶å¤±è´¥å¤šä¸ª stages**
```python
# åˆ›å»º pipeline with 3 å¹¶è¡Œ stages
stages = [
    {"name": "A", "task": "train_model", "params": {...}, "depends_on": []},
    {"name": "B", "task": "train_model", "params": {...}, "depends_on": []},
    {"name": "C", "task": "train_model", "params": {...}, "depends_on": []},
]

# è®©å®ƒä»¬åŒæ—¶å¤±è´¥
# è§‚å¯Ÿ DBï¼špipeline.status åº”è¯¥æ˜¯ FAILED
# è§‚å¯Ÿæ—¥å¿—ï¼šåº”è¯¥åªæœ‰ä¸€ä¸ª stage æˆåŠŸæ ‡è®° FAILEDï¼Œå…¶ä»–çš„è®°å½• warning
```

### 2. éªŒè¯ Worker éš”ç¦»

**æµ‹è¯•åœºæ™¯ï¼šè®­ç»ƒä¸­è§¦å‘çŸ­ä»»åŠ¡**
```bash
# å¯åŠ¨ workers
docker-compose -f docker-compose.celery.yml up -d

# æäº¤è®­ç»ƒä»»åŠ¡
curl -X POST http://localhost:8000/api/jobs \
  -H "Content-Type: application/json" \
  -d '{"name": "test", "algorithm": "ppo", ...}'

# åœ¨è®­ç»ƒè¿è¡Œæ—¶ï¼Œè§¦å‘ update_metrics
# è§‚å¯Ÿï¼šupdate_metrics åº”è¯¥åœ¨ < 10 ç§’å†…å®Œæˆï¼Œä¸å—è®­ç»ƒä»»åŠ¡å½±å“

# æŸ¥çœ‹ Flower
open http://localhost:5555
# åº”è¯¥çœ‹åˆ°ï¼š
# - celery_worker_training: 1 active (training task)
# - celery_worker_short: 0 active (å·²å®Œæˆ update_metrics)
```

### 3. éªŒè¯å‘¨æœŸä»»åŠ¡

```bash
# æŸ¥çœ‹ beat æ—¥å¿—
docker-compose -f docker-compose.celery.yml logs -f celery_beat

# åº”è¯¥æ¯åˆ†é’Ÿçœ‹åˆ°ï¼š
# [beat] Scheduler: Sending due task update_job_metrics
```

---

**æ‰€æœ‰å…³é”®é—®é¢˜å·²ä¿®å¤ï¼Œå¹³å°è§„æ¨¡åŒ–å°±ç»ªï¼** âœ…
