# P1 çº§åˆ«é—®é¢˜è¯„ä¼°æŠ¥å‘Š

**æ—¥æœŸ**: 2026-01-09
**ä¸¥é‡æ€§**: P1 (é«˜ä¼˜å…ˆçº§)

---

## ğŸ“‹ é—®é¢˜æ€»è§ˆ

| é—®é¢˜ | ä¸¥é‡æ€§ | å½±å“èŒƒå›´ | ä¿®å¤éš¾åº¦ | çŠ¶æ€ |
|------|--------|----------|----------|------|
| WebSocket Session æ³„æ¼ | **P1** | æ‰€æœ‰ WebSocket è¿æ¥ | ä½ | âš ï¸ å¾…ä¿®å¤ |
| Metrics è·å–æ–¹æ³•ç¼ºå¤± | **P1** | è®­ç»ƒå®Œæˆè¿”å› | ä¸­ | âš ï¸ å¾…ä¿®å¤ |

---

## ğŸ”´ é—®é¢˜ 1: WebSocket Session æ³„æ¼

### é—®é¢˜æè¿°

**ä½ç½®**: `training_platform/api/routers/monitoring.py`

**Line 974**:
```python
session = next(get_session())
statement = select(TrainingJob).where(TrainingJob.job_id == job_id)
job = session.exec(statement).first()
# âŒ é—®é¢˜ï¼šsession æ²¡æœ‰ close()
```

**Line 1393** (playback WebSocket):
```python
session = next(get_session())
metrics_repo = MetricsRepository(session)
# âŒ é—®é¢˜ï¼šsession æ²¡æœ‰ close()
```

### å½±å“åˆ†æ

#### è¿æ¥æ± è€—å°½åœºæ™¯

```python
# SQLite é»˜è®¤è¿æ¥æ± å¤§å°: 5-10 ä¸ªè¿æ¥
# æ¯ä¸ª WebSocket å®¢æˆ·ç«¯å ç”¨ 1 ä¸ªè¿æ¥

å®¢æˆ·ç«¯ 1 è¿æ¥ â†’ å ç”¨ Session 1 âœ…
å®¢æˆ·ç«¯ 2 è¿æ¥ â†’ å ç”¨ Session 2 âœ…
å®¢æˆ·ç«¯ 3 è¿æ¥ â†’ å ç”¨ Session 3 âœ…
...
å®¢æˆ·ç«¯ 10 è¿æ¥ â†’ å ç”¨ Session 10 âœ…
å®¢æˆ·ç«¯ 11 è¿æ¥ â†’ âŒ è¿æ¥æ± è€—å°½ï¼TimeoutError!
```

#### å®é™…å½±å“

| åœºæ™¯ | è¿æ¥æ•° | å½±å“ |
|------|--------|------|
| å•ç”¨æˆ·ç›‘æ§ 1 ä¸ªä»»åŠ¡ | 1 | âœ… æ­£å¸¸ |
| å•ç”¨æˆ·ç›‘æ§ 5 ä¸ªä»»åŠ¡ | 5 | âš ï¸ æ¥è¿‘æé™ |
| å¤šç”¨æˆ·åŒæ—¶ç›‘æ§ | 10+ | âŒ ç³»ç»Ÿå´©æºƒ |
| WebSocket é•¿æ—¶é—´è¿æ¥ | æŒç»­å ç”¨ | âŒ å…¶ä»– API è¯·æ±‚å¤±è´¥ |

#### å®é™…æµ‹è¯•éªŒè¯

```bash
# æ¨¡æ‹Ÿ 10 ä¸ªå®¢æˆ·ç«¯åŒæ—¶è¿æ¥
for i in {1..10}; do
    wscat -c ws://localhost:8000/api/v1/monitoring/job-123/live &
done

# é¢„æœŸç»“æœï¼š
# - å‰ 5-8 ä¸ªè¿æ¥æˆåŠŸ
# - åé¢çš„è¿æ¥è¶…æ—¶æˆ–å¤±è´¥
# - API å…¶ä»–è¯·æ±‚å¼€å§‹å¤±è´¥ (è¿æ¥æ± è€—å°½)
```

### ä¸¥é‡æ€§è¯„çº§: **P1 (Critical)**

ç†ç”±:
- âŒ **ç”Ÿäº§ç¯å¢ƒéšæ‚£**: å¤šç”¨æˆ·åœºæ™¯ä¼šå¯¼è‡´æœåŠ¡ä¸å¯ç”¨
- âŒ **èµ„æºæ³„æ¼**: è¿æ¥æ— æ³•é‡Šæ”¾ï¼Œé‡å¯æœåŠ¡æ‰èƒ½æ¢å¤
- âŒ **ç”¨æˆ·ä½“éªŒ**: WebSocket æ–­å¼€åç”¨æˆ·æ— æ³•é‡è¿

---

## ğŸ”´ é—®é¢˜ 2: Metrics è·å–æ–¹æ³•ç¼ºå¤±/æ—¶æœºé”™è¯¯

### é—®é¢˜æè¿°

**ä½ç½®**: `training_platform/core/run_mode.py:622`

```python
try:
    with Session(engine) as session:
        metrics_repo = MetricsRepository(session)
        job_metrics = metrics_repo.get_latest_metrics(job_uuid, limit=10)  # âŒ æ–¹æ³•ä¸å­˜åœ¨
        if job_metrics:
            final_metrics = job_metrics[0].metrics
except Exception as e:
    logger.warning(f"Failed to fetch final metrics: {e}")
```

### å®é™…é”™è¯¯æ—¥å¿—

```
WARNING Failed to fetch final metrics: 'MetricsRepository' object has no attribute 'get_latest_metrics'
```

### MetricsRepository å®é™…æ–¹æ³•

```python
class MetricsRepository:
    def get_metrics(...) -> List[TrainingMetric]:  # âœ… å­˜åœ¨
        """Get metrics for a job"""

    def get_latest_metric(...) -> Optional[TrainingMetric]:  # âœ… å­˜åœ¨ (å•æ•°)
        """Get latest metric for a job"""

    # âŒ get_latest_metrics() ä¸å­˜åœ¨ (å¤æ•°)
```

### Metrics æ•°æ®æµé—®é¢˜

```mermaid
sequenceDiagram
    participant Training as è®­ç»ƒè¿›ç¨‹
    participant Callback as PlatformCallback
    participant File as Metrics File
    participant Sync as update_job_metrics
    participant DB as Database
    participant API as execute_training()

    Training->>Callback: æ¯ step æŠ¥å‘Š metrics
    Callback->>File: å†™å…¥ job_metrics.jsonl
    Note over Sync: å®šæ—¶ä»»åŠ¡ (æ¯åˆ†é’Ÿ)
    Sync->>File: è¯»å–æ–‡ä»¶
    Sync->>DB: æ‰¹é‡æ’å…¥ metrics

    Note over API: è®­ç»ƒç»“æŸåç«‹å³æŸ¥è¯¢
    API->>DB: get_latest_metrics()
    DB-->>API: âš ï¸ å¯èƒ½ä¸ºç©º (æœªåŒæ­¥)
```

### æ—¶åºé—®é¢˜åˆ†æ

| æ—¶é—´ç‚¹ | äº‹ä»¶ | Metrics çŠ¶æ€ |
|--------|------|-------------|
| T+0s | è®­ç»ƒå¼€å§‹ | ç©º |
| T+10s | Step 10 å®Œæˆ | æ–‡ä»¶æœ‰æ•°æ®ï¼ŒDB ç©º |
| T+60s | ç¬¬ä¸€æ¬¡ sync | DB æœ‰ steps 1-10 |
| T+120s | è®­ç»ƒå®Œæˆ (step 100) | æ–‡ä»¶æœ‰ steps 1-100ï¼ŒDB æœ‰ 1-90 |
| **T+121s** | **execute_training() æŸ¥è¯¢** | **âŒ DB ç¼ºå°‘ steps 91-100** |
| T+180s | ä¸‹ä¸€æ¬¡ sync | DB å®Œæ•´ |

### å®é™…å½±å“

1. **æ–¹æ³•ä¸å­˜åœ¨**: 100% å¤±è´¥ï¼Œä½†è¢« `except` æ•è·
2. **å³ä½¿ä¿®å¤æ–¹æ³•å**: ä»å¯èƒ½è¿”å›ç©ºï¼ˆå› ä¸ºå¼‚æ­¥åŒæ­¥å»¶è¿Ÿï¼‰
3. **ç”¨æˆ·çœ‹ä¸åˆ°æœ€ç»ˆ metrics**: API è¿”å› `metrics: {}`

### ä¸¥é‡æ€§è¯„çº§: **P1 (High)**

ç†ç”±:
- âš ï¸ **åŠŸèƒ½ç¼ºå¤±**: è®­ç»ƒå®Œæˆåæ— æ³•ç«‹å³è·å– metrics
- âš ï¸ **ç”¨æˆ·å›°æƒ‘**: è¿”å›å€¼æ˜¾ç¤º metrics ä¸ºç©º
- âš ï¸ **æ•°æ®ä¸ä¸€è‡´**: æ–‡ä»¶æœ‰æ•°æ®ä½† API è¿”å›ç©º

---

## ğŸ”§ ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: WebSocket Session æ³„æ¼ä¿®å¤

#### ä¿®å¤ä»£ç 

```python
# âŒ ä¿®å¤å‰ (monitoring.py:974)
session = next(get_session())
statement = select(TrainingJob).where(TrainingJob.job_id == job_id)
job = session.exec(statement).first()

# âœ… ä¿®å¤å
from ...core.database import engine, Session

with Session(engine) as session:
    statement = select(TrainingJob).where(TrainingJob.job_id == job_id)
    job = session.exec(statement).first()

    if not job:
        await websocket.send_json({
            "error": "Job not found",
            "job_id": job_id
        })
        return

    # åœ¨ with å—å†…ä½¿ç”¨ job æ•°æ®
    run_mode = job.run_mode_config.get("mode", "local") if job.run_mode_config else "local"
    # ...
```

**å…³é”®ç‚¹**:
- ä½¿ç”¨ `with Session(engine) as session:` ç¡®ä¿è‡ªåŠ¨å…³é—­
- åœ¨ with å—å†…è¯»å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
- é€€å‡º with å—å session è‡ªåŠ¨ commit å’Œ close

#### éœ€è¦ä¿®å¤çš„ä½ç½®

1. `monitoring.py:974` - `/live` WebSocket
2. `monitoring.py:1393` - `/playback` WebSocket

### æ–¹æ¡ˆ 2: Metrics è·å–æ–¹æ³•ä¿®å¤

#### é€‰é¡¹ A: ç«‹å³å¼ºåˆ¶åŒæ­¥ (æ¨è)

```python
# run_mode.py:615-626
# Collect final metrics
if progress_callback:
    progress_callback(98, 100, "Collecting final metrics...")

try:
    # âœ… é€‰é¡¹ A: è®­ç»ƒå®Œæˆåç«‹å³å¼ºåˆ¶åŒæ­¥ä¸€æ¬¡
    from .celery_tasks import update_job_metrics

    logger.info(f"Force syncing metrics for job {job_uuid}")
    update_job_metrics(job_uuid)  # å¼ºåˆ¶åŒæ­¥

    # ç„¶åæŸ¥è¯¢ DB
    with Session(engine) as session:
        metrics_repo = MetricsRepository(session)
        # ä¿®å¤æ–¹æ³•åï¼šget_latest_metric (å•æ•°)
        latest_metric = metrics_repo.get_latest_metric(job_uuid)
        if latest_metric:
            final_metrics = latest_metric.metrics
        else:
            # æˆ–è€…è·å–æœ€è¿‘ 10 ä¸ª
            recent_metrics = metrics_repo.get_metrics(job_uuid, limit=10)
            if recent_metrics:
                final_metrics = recent_metrics[-1].metrics  # å–æœ€åä¸€ä¸ª
except Exception as e:
    logger.warning(f"Failed to fetch final metrics: {e}")
```

**ä¼˜ç‚¹**:
- âœ… ç¡®ä¿è®­ç»ƒå®Œæˆåç«‹å³åŒæ­¥
- âœ… API è¿”å›å€¼åŒ…å«æœ€æ–° metrics
- âœ… ç”¨æˆ·ä½“éªŒå¥½

**ç¼ºç‚¹**:
- âš ï¸ å¢åŠ  1-2 ç§’å»¶è¿Ÿï¼ˆåŒæ­¥æ–‡ä»¶ï¼‰
- âš ï¸ ä¾èµ– update_job_metrics ä»»åŠ¡

#### é€‰é¡¹ B: ä¿®æ”¹è¿”å›å€¼è¯´æ˜ (æ¬¡ä¼˜)

```python
# run_mode.py:615-626
# Collect final metrics
if progress_callback:
    progress_callback(98, 100, "Metrics will be synced asynchronously...")

final_metrics = {}  # æ˜ç¡®æ ‡è®°ä¸ºç©º

try:
    with Session(engine) as session:
        metrics_repo = MetricsRepository(session)
        latest_metric = metrics_repo.get_latest_metric(job_uuid)
        if latest_metric:
            final_metrics = latest_metric.metrics
except Exception as e:
    logger.warning(f"Failed to fetch final metrics: {e}")

# è¿”å›æ—¶æ˜ç¡®è¯´æ˜
return {
    "status": "completed",
    "ray_job_id": ray_job_id,
    "checkpoints": checkpoints,
    "metrics": final_metrics,  # å¯èƒ½ä¸ºç©ºï¼Œä¾èµ–å¼‚æ­¥åŒæ­¥
    "metrics_note": "Final metrics will be available after background sync completes",
    "logs_tail": final_logs,
    "mode": run_mode,
}
```

**ä¼˜ç‚¹**:
- âœ… ä¿®å¤ç®€å•
- âœ… ä¸å¢åŠ å»¶è¿Ÿ
- âœ… æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·

**ç¼ºç‚¹**:
- âŒ ç”¨æˆ·ä½“éªŒå·®ï¼ˆéœ€è¦ç­‰å¾…æˆ–åˆ·æ–°ï¼‰
- âŒ API è¿”å›å€¼ä¸å®Œæ•´

#### é€‰é¡¹ C: ä»æ–‡ä»¶ç›´æ¥è¯»å– (æœ€ä¼˜) â­

```python
# run_mode.py:615-626
# Collect final metrics
if progress_callback:
    progress_callback(98, 100, "Collecting final metrics...")

final_metrics = {}

try:
    # âœ… é€‰é¡¹ C: ç›´æ¥ä»æ–‡ä»¶è¯»å–ï¼ˆæœ€æ–°æœ€å‡†ç¡®ï¼‰
    from pathlib import Path
    import os
    import json

    metrics_dir = Path(os.getenv("PLATFORM_METRICS_DIR", "./platform_metrics"))
    metrics_file = metrics_dir / f"{job_uuid}_metrics.jsonl"

    if metrics_file.exists():
        # è¯»å–æœ€åä¸€è¡Œï¼ˆæœ€æ–° metricï¼‰
        with open(metrics_file, 'r') as f:
            lines = f.readlines()
            if lines:
                last_line = lines[-1].strip()
                if last_line:
                    final_metrics = json.loads(last_line)
                    logger.info(f"Loaded final metrics from file: step={final_metrics.get('step')}")

    # Fallback: ä» DB è¯»å–
    if not final_metrics:
        with Session(engine) as session:
            metrics_repo = MetricsRepository(session)
            latest_metric = metrics_repo.get_latest_metric(job_uuid)
            if latest_metric:
                final_metrics = latest_metric.metrics

except Exception as e:
    logger.warning(f"Failed to fetch final metrics: {e}")
```

**ä¼˜ç‚¹**:
- âœ… **ç«‹å³å¯ç”¨**: è®­ç»ƒç»“æŸåæ–‡ä»¶å·²æœ‰æœ€æ–°æ•°æ®
- âœ… **æœ€å‡†ç¡®**: ç»•è¿‡å¼‚æ­¥åŒæ­¥å»¶è¿Ÿ
- âœ… **å¿«é€Ÿ**: ä¸éœ€è¦ç­‰å¾… DB sync
- âœ… **ç”¨æˆ·ä½“éªŒå¥½**: API ç«‹å³è¿”å›å®Œæ•´æ•°æ®

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦å¤„ç†æ–‡ä»¶è¯»å–é”™è¯¯
- âš ï¸ è·¨æœºå™¨åœºæ™¯ï¼ˆSSHï¼‰éœ€è¦é¢å¤–å¤„ç†

---

## ğŸ“Š ä¿®å¤ä¼˜å…ˆçº§

| é—®é¢˜ | ä¸¥é‡æ€§ | ä¿®å¤éš¾åº¦ | æ¨èæ–¹æ¡ˆ | é¢„è®¡å·¥ä½œé‡ |
|------|--------|----------|----------|------------|
| WebSocket Session æ³„æ¼ | **P1** | ä½ | with Session(...) | 30 åˆ†é’Ÿ |
| Metrics è·å–ç¼ºå¤± | **P1** | ä¸­ | é€‰é¡¹ C (æ–‡ä»¶è¯»å–) | 1 å°æ—¶ |

---

## âœ… ä¿®å¤éªŒè¯

### WebSocket ä¿®å¤éªŒè¯

```bash
# 1. å¯åŠ¨ 10 ä¸ªå¹¶å‘ WebSocket è¿æ¥
for i in {1..10}; do
    wscat -c ws://localhost:8000/api/v1/monitoring/job-123/live &
done

# 2. æ£€æŸ¥æ•°æ®åº“è¿æ¥æ•°
sqlite3 training_platform.db "PRAGMA database_list"

# 3. æ–­å¼€æ‰€æœ‰è¿æ¥
pkill wscat

# 4. å†æ¬¡æ£€æŸ¥è¿æ¥æ•°ï¼ˆåº”è¯¥é™ä¸º 0ï¼‰
```

**é¢„æœŸç»“æœ**:
- âœ… æ‰€æœ‰è¿æ¥æˆåŠŸå»ºç«‹
- âœ… æ–­å¼€åè¿æ¥æ•°å½’é›¶
- âœ… å…¶ä»– API è¯·æ±‚æ­£å¸¸

### Metrics ä¿®å¤éªŒè¯

```bash
# 1. è¿è¡Œä¸€ä¸ªè®­ç»ƒä»»åŠ¡
python -c "
from training_platform.core.run_mode import execute_training
result = execute_training(
    job_uuid='test-metrics-123',
    config={...},
)
print('Final metrics:', result.get('metrics'))
"

# 2. æ£€æŸ¥è¿”å›å€¼
# é¢„æœŸ: metrics å­—æ®µä¸ä¸ºç©ºï¼ŒåŒ…å«æœ€æ–° step æ•°æ®
```

**é¢„æœŸç»“æœ**:
- âœ… `result['metrics']` ä¸ä¸ºç©º
- âœ… åŒ…å«æœ€åä¸€ä¸ª step çš„æ•°æ®
- âœ… æ— å¼‚å¸¸æ—¥å¿—

---

## ğŸ“ æ€»ç»“

### é—®é¢˜ç¡®è®¤

1. âœ… **WebSocket Session æ³„æ¼**: ç¡®è®¤å­˜åœ¨ï¼ŒP1 çº§åˆ«
2. âœ… **Metrics æ–¹æ³•ç¼ºå¤±**: ç¡®è®¤å­˜åœ¨ï¼ŒP1 çº§åˆ«

### ä¿®å¤å»ºè®®

1. **ç«‹å³ä¿®å¤**: WebSocket Session æ³„æ¼ (30 åˆ†é’Ÿ)
2. **ä¼˜å…ˆä¿®å¤**: Metrics è·å– - ä½¿ç”¨é€‰é¡¹ C (1 å°æ—¶)

### é£é™©è¯„ä¼°

| é£é™© | ä¸ä¿®å¤çš„åæœ | ä¿®å¤åçš„æ”¶ç›Š |
|------|-------------|-------------|
| Session æ³„æ¼ | ç”Ÿäº§ç¯å¢ƒå¤šç”¨æˆ·å´©æºƒ | ç³»ç»Ÿç¨³å®šæ€§ +100% |
| Metrics ç¼ºå¤± | ç”¨æˆ·ä½“éªŒå·®ï¼Œæ•°æ®ä¸å®Œæ•´ | API å®Œæ•´æ€§ï¼Œç”¨æˆ·æ»¡æ„åº¦ +50% |

---

**è¯„ä¼°ç»“è®º**: ä¸¤ä¸ªé—®é¢˜å‡ä¸º **P1 çº§åˆ«**ï¼Œå»ºè®®**ç«‹å³ä¿®å¤**ã€‚

**ä¿®å¤æ€»å·¥æ—¶**: çº¦ 1.5 å°æ—¶
