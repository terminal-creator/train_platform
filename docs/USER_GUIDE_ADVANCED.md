# 高级功能用户指南 - 数据集、评估、模型手术

**补充文档**: 完整训练流程的高级步骤
**前端地址**: `http://localhost:5173`
**API地址**: `http://localhost:8000`

---

## 📋 目录

- [Step 2: 数据集管理](#step-2-数据集管理)
- [Step 8: 自定义评估](#step-8-自定义评估)
- [Step 9: 模型手术](#step-9-模型手术)
- [完整训练流程](#完整训练流程)

---

## Step 2: 数据集管理

**在训练前，你需要准备和管理数据集**

### 2.1 进入数据集页面

1. 点击左侧导航栏的 **"数据集"** (Datasets)
2. 你会看到数据集列表页面

### 2.2 查看现有数据集

数据集列表显示：
```
┌─────────────────────────────────────────────┐
│  数据集列表                                  │
├─────────────────────────────────────────────┤
│  📁 sales_sft.jsonl                         │
│     类型: SFT   大小: 1.2 MB   样本数: 500   │
│                                             │
│  📁 sales_dpo.jsonl                         │
│     类型: DPO   大小: 2.3 MB   样本数: 300   │
│                                             │
│  📁 ppo_general.json                        │
│     类型: PPO   大小: 850 KB   样本数: 200   │
│                                             │
│  📁 sales_grpo.jsonl                        │
│     类型: GRPO  大小: 1.5 MB   样本数: 400   │
└─────────────────────────────────────────────┘
```

### 2.3 上传新数据集

#### 方法 1: 通过前端上传

1. 点击右上角 **"+ 上传数据集"** 按钮
2. 填写数据集信息：

   ```
   数据集名称:   my_custom_dataset
   描述:         我的自定义训练数据
   数据格式:     SFT / DPO / PPO / GRPO (选择)
   ```

3. 点击 **"选择文件"** 按钮，选择本地文件
4. 点击 **"上传"** 按钮

**支持的格式**:
- `.jsonl` (推荐)
- `.json`
- `.txt`
- `.csv`

#### 方法 2: 直接放到 datasets 目录

```bash
# 直接复制文件到 datasets 目录
cp my_dataset.jsonl train_platform/datasets/

# 刷新前端页面，新数据集会自动显示
```

### 2.4 预览数据集内容

1. 点击数据集名称
2. 弹出数据预览窗口

**预览内容**:
```json
// SFT 数据预览
{
  "prompt": "如何提高销售业绩？",
  "response": "提高销售业绩的关键在于..."
}

// DPO 数据预览
{
  "prompt": "推荐一款手机",
  "chosen": "我推荐 iPhone 15，因为...",
  "rejected": "随便买一个就行"
}

// PPO 数据预览
{
  "prompt": "解释量子计算"
}

// GRPO 数据预览
{
  "prompt": "计算: 2x + 3 = 11，求 x",
  "solution": "4"
}
```

### 2.5 验证数据格式

点击数据集行的 **"验证"** 按钮

系统会检查：
- ✅ 数据格式是否正确
- ✅ 必需字段是否存在
- ✅ 数据类型是否匹配
- ✅ 特殊字符是否正确编码

**验证结果示例**:
```
✓ 数据格式: 正确
✓ 样本数量: 500
✓ 必需字段: prompt, response
✓ 平均 prompt 长度: 45 tokens
✓ 平均 response 长度: 128 tokens
⚠ 警告: 3 个样本的 response 超过 512 tokens
```

### 2.6 编辑数据集信息

1. 点击数据集行的 **"编辑"** 按钮
2. 修改名称或描述
3. 点击 **"保存"**

### 2.7 删除数据集

1. 点击数据集行的 **"删除"** 按钮
2. 确认删除操作

⚠️ **警告**: 删除数据集不会删除物理文件，只是从列表移除

### 2.8 数据集统计

点击 **"统计"** 按钮查看详细信息：

```
数据集统计: sales_sft.jsonl
├─ 总样本数: 500
├─ 文件大小: 1.2 MB
├─ 平均 prompt 长度: 45 tokens (最短: 10, 最长: 120)
├─ 平均 response 长度: 128 tokens (最短: 20, 最长: 512)
├─ 重复样本: 3 (0.6%)
└─ 编码格式: UTF-8
```

### 2.9 数据集去重（高级功能）

如果数据集有重复：

1. 点击 **"去重"** 按钮
2. 选择去重方式：
   - **精确匹配**: 完全相同的样本
   - **语义相似**: 使用 embedding 检测相似样本

3. 设置相似度阈值（语义相似）: `0.95`
4. 点击 **"开始去重"**

**去重结果**:
```
去重完成:
├─ 原始样本: 500
├─ 删除重复: 15
├─ 最终样本: 485
└─ 新文件: sales_sft_dedup.jsonl
```

### 2.10 数据集版本管理（高级功能）

创建数据集版本：

1. 点击数据集的 **"版本"** 按钮
2. 点击 **"创建新版本"**
3. 填写版本信息：

   ```
   版本号:   v1.1
   描述:     添加 100 个新样本，修复格式错误
   ```

4. 点击 **"创建"**

**版本列表**:
```
sales_sft.jsonl 版本历史:
├─ v1.1 (当前) - 2024-01-09 14:30 - 500 样本
├─ v1.0         - 2024-01-08 10:00 - 400 样本
└─ v0.9         - 2024-01-07 15:00 - 300 样本
```

### 2.11 使用数据集进行训练

在创建训练任务时：

1. **训练数据路径**: 可以输入或选择
   ```
   方式 1: 手动输入
   ./datasets/sales_sft.jsonl

   方式 2: 点击 "选择" 按钮
   从列表中选择数据集
   ```

2. **验证数据路径** (可选):
   ```
   ./datasets/sales_sft_val.jsonl
   ```

3. 系统会自动验证路径是否存在

---

## Step 8: 自定义评估

**训练完成后，评估模型性能**

### 8.1 评估的重要性

为什么需要评估？
- ✅ 客观衡量模型性能
- ✅ 对比不同 checkpoint
- ✅ 发现过拟合问题
- ✅ 选择最佳模型

### 8.2 进入评估页面

1. 训练完成后，点击左侧导航栏 **"评估"** (Evaluation)
2. 或在任务详情页点击 **"创建评估"** 按钮

### 8.3 准备评估数据集

#### 方法 1: 使用预置评估集

系统提供常见评估基准：
- **MMLU**: 多任务语言理解
- **GSM8K**: 数学推理
- **HumanEval**: 代码生成
- **TruthfulQA**: 真实性评估
- **自定义**: 上传自己的评估集

#### 方法 2: 上传自定义评估集

1. 点击 **"评估数据集"** 标签页
2. 点击 **"+ 上传评估集"**
3. 填写评估集信息：

   ```
   名称:         销售场景评估集
   描述:         评估销售对话能力
   评估能力:     对话质量
   评估方法:     模型打分 (Model-as-Judge)
   样本数:       100
   ```

4. 上传数据文件 (格式示例)：

   ```jsonl
   {
     "prompt": "客户问：价格能便宜点吗？",
     "reference": "我们的价格已经很优惠了，但我可以帮您申请额外折扣",
     "label": "good"
   }
   ```

**评估集格式**:
```jsonl
{
  "prompt": "输入问题",           // 必需
  "reference": "参考答案",        // 可选，用于对比
  "label": "正确标签",            // 可选，用于分类任务
  "metadata": {...}               // 可选，额外信息
}
```

### 8.4 创建评估任务

#### Step 1: 选择要评估的模型

```
模型类型: Checkpoint
选择来源:
  ○ 从训练任务选择
  ○ 手动输入路径
```

**从训练任务选择**:
1. 选择训练任务: `SFT Sales Training`
2. 选择 checkpoint: `checkpoint-100` (最终模型)

**手动输入路径**:
```
模型路径: ./checkpoints/sft-sales-123/checkpoint-100
```

#### Step 2: 选择评估数据集

```
评估数据集: 销售场景评估集 (100 样本)
```

#### Step 3: 配置评估方法

**方法 1: 模型打分 (Model-as-Judge)** ⭐ 推荐

```
评估方式:     模型打分
评判模型:     GPT-4 / Claude / Qwen-Plus
API Key:      sk-xxxxx
评分维度:
  □ 准确性 (Accuracy)
  □ 相关性 (Relevance)
  □ 流畅性 (Fluency)
  □ 专业性 (Professionalism)
```

**评判 Prompt 模板**:
```
你是一个专业的评估者。请对以下对话回复进行评分(1-5分):

输入: {prompt}
模型回复: {response}
参考答案: {reference}

请从以下维度评分:
1. 准确性: 回答是否准确
2. 相关性: 回答是否切题
3. 流畅性: 语言是否自然
4. 专业性: 是否体现专业知识

输出格式 (JSON):
{
  "accuracy": 4,
  "relevance": 5,
  "fluency": 4,
  "professionalism": 5,
  "reason": "回答准确且专业..."
}
```

**方法 2: 自动指标**

```
评估方式: 自动指标
指标选择:
  □ BLEU (机器翻译质量)
  □ ROUGE (摘要质量)
  □ Perplexity (困惑度)
  □ Exact Match (精确匹配)
```

**方法 3: 人工评估**

```
评估方式: 人工评估
导出格式: Excel / CSV
评估表格:
  - 包含 prompt、模型输出、评分栏
  - 评估者填写后上传
```

#### Step 4: 配置推理参数

```
推理引擎:     vLLM (推荐) / HuggingFace
批次大小:     8
最大长度:     512
Temperature:  0.7
Top-p:        0.9
```

#### Step 5: 高级配置（可选）

```
并发推理:     4 (同时处理多个样本)
超时时间:     60 秒/样本
失败重试:     3 次
保存输出:     ✓ 保存所有模型输出
```

### 8.5 启动评估任务

1. 检查所有配置
2. 点击 **"开始评估"** 按钮
3. 任务提交到后台队列

### 8.6 监控评估进度

评估页面显示：

```
┌─────────────────────────────────────────┐
│  评估任务: SFT Sales - 销售场景评估     │
├─────────────────────────────────────────┤
│  状态: 运行中 ⏳                         │
│  进度: 45/100 (45%)                      │
│  耗时: 2 分 30 秒                        │
│  预计剩余: 3 分钟                        │
├─────────────────────────────────────────┤
│  实时统计:                               │
│  ├─ 平均准确性: 4.2/5                   │
│  ├─ 平均相关性: 4.5/5                   │
│  ├─ 平均流畅性: 4.3/5                   │
│  └─ 平均专业性: 4.4/5                   │
└─────────────────────────────────────────┘
```

### 8.7 查看评估结果

评估完成后，点击 **"查看结果"**

#### 总体指标

```
评估结果总览:
┌─────────────────────────────────────────┐
│  总样本数: 100                           │
│  成功: 98   失败: 2                      │
│  平均耗时: 3.2 秒/样本                   │
├─────────────────────────────────────────┤
│  评分结果:                               │
│  ├─ 准确性: 4.2/5  ████████░░ (84%)     │
│  ├─ 相关性: 4.5/5  █████████░ (90%)     │
│  ├─ 流畅性: 4.3/5  ████████░░ (86%)     │
│  └─ 专业性: 4.4/5  ████████░░ (88%)     │
├─────────────────────────────────────────┤
│  综合得分: 4.35/5  ████████░░ (87%)     │
└─────────────────────────────────────────┘
```

#### 详细结果列表

```
样本详情 (前 5 个):

样本 #1:
├─ 输入: "客户问：价格能便宜点吗？"
├─ 模型输出: "我们的价格已经很优惠了..."
├─ 参考答案: "我们的价格已经很优惠了..."
├─ 评分: ⭐⭐⭐⭐⭐ (5/5)
└─ 评语: "回答专业且得体"

样本 #2:
├─ 输入: "这款产品有什么优势？"
├─ 模型输出: "主要优势包括..."
├─ 评分: ⭐⭐⭐⭐☆ (4/5)
└─ 评语: "回答准确但略显生硬"

样本 #3:
├─ 输入: "售后服务怎么样？"
├─ 模型输出: "我们提供完善的售后..."
├─ 评分: ⭐⭐⭐⭐⭐ (5/5)
└─ 评语: "回答全面且专业"
```

#### 错误分析

```
失败样本分析:

样本 #45:
├─ 错误类型: 推理超时
├─ 输入: "复杂的技术问题..."
└─ 原因: 输入过长，超过最大长度限制

样本 #78:
├─ 错误类型: 模型输出格式错误
├─ 输入: "价格查询"
└─ 原因: 模型输出无法解析
```

#### 分数分布

```
评分分布直方图:

5分: ████████████████████████ 35%
4分: ████████████████████████████ 40%
3分: ████████████ 18%
2分: ████ 5%
1分: ██ 2%
```

### 8.8 对比多个模型

**场景**: 对比不同 checkpoint 或不同训练方法

#### Step 1: 创建对比评估

1. 点击 **"创建对比"** 按钮
2. 选择要对比的模型：

   ```
   模型 A: SFT Sales - checkpoint-100 (最终)
   模型 B: SFT Sales - checkpoint-50  (中期)
   模型 C: SFT LoRA - checkpoint-100  (LoRA 版本)
   ```

3. 选择评估数据集: `销售场景评估集`
4. 点击 **"开始对比"**

#### Step 2: 查看对比结果

```
模型对比结果:
┌─────────────┬─────────┬─────────┬─────────┐
│   指标      │ 模型 A  │ 模型 B  │ 模型 C  │
├─────────────┼─────────┼─────────┼─────────┤
│ 准确性      │ 4.2     │ 3.8     │ 4.0     │
│ 相关性      │ 4.5     │ 4.2     │ 4.3     │
│ 流畅性      │ 4.3     │ 4.0     │ 4.2     │
│ 专业性      │ 4.4     │ 3.9     │ 4.1     │
├─────────────┼─────────┼─────────┼─────────┤
│ 综合得分    │ 4.35 ⭐ │ 3.98    │ 4.15    │
│ 推理速度    │ 3.2s    │ 3.0s    │ 2.1s ⭐ │
│ 显存占用    │ 8.5GB   │ 8.5GB   │ 2.3GB ⭐│
└─────────────┴─────────┴─────────┴─────────┘

结论:
- 模型 A (最终 checkpoint) 性能最佳
- 模型 C (LoRA) 速度快、显存小，性能接近
- 模型 B (中期) 性能偏低，继续训练有效
```

#### 详细对比 - 逐样本

```
样本 #1: "客户问：价格能便宜点吗？"

模型 A 输出: "我们的价格已经很优惠了..." ⭐⭐⭐⭐⭐
模型 B 输出: "价格不能降了" ⭐⭐☆☆☆
模型 C 输出: "我们的价格已经是最低的..." ⭐⭐⭐⭐☆

最佳: 模型 A
```

### 8.9 导出评估报告

点击 **"导出报告"** 按钮

**导出格式**:
- **PDF**: 完整的评估报告（图表+分析）
- **Excel**: 详细评估结果（每个样本）
- **JSON**: 原始数据（用于进一步分析）

**报告内容**:
```
评估报告.pdf
├─ 1. 执行摘要
│   ├─ 评估概述
│   ├─ 主要发现
│   └─ 建议
├─ 2. 评估方法
│   ├─ 数据集说明
│   ├─ 评估指标
│   └─ 评判标准
├─ 3. 评估结果
│   ├─ 总体指标
│   ├─ 分数分布
│   ├─ 详细样本
│   └─ 错误分析
├─ 4. 模型对比（如有）
│   ├─ 性能对比
│   ├─ 效率对比
│   └─ 成本对比
└─ 5. 结论与建议
    ├─ 模型优势
    ├─ 存在问题
    └─ 改进方向
```

### 8.10 自动评估（集成到训练）

**高级功能**: 训练时自动评估

在创建训练任务时：

1. 展开 **"评估配置"** (可选)
2. 启用 **"训练中自动评估"**
3. 配置：

   ```
   评估频率:     每 50 steps
   评估数据集:   销售场景评估集 (小样本，10个)
   评估方法:     自动指标 (BLEU, ROUGE)
   ```

4. 训练时会自动评估并记录

**效果**:
- 在监控页面看到评估指标曲线
- 及时发现过拟合（评估分数下降）
- 自动选择最佳 checkpoint

---

## Step 9: 模型手术

**训练完成后，对模型进行高级操作**

### 9.1 什么是模型手术？

模型手术包括：
- 🔀 **模型合并**: 合并多个模型的优势
- 📊 **Checkpoint 选择**: 自动选择最佳检查点
- ⚖️ **权重平均**: 平滑模型权重
- 🎯 **模型压缩**: 减小模型大小
- 🧬 **LoRA 合并**: 将 LoRA 合并回基础模型

### 9.2 进入模型手术页面

1. 点击左侧导航栏 **"模型手术"** (Model Surgery)
2. 或在任务详情页点击 **"模型手术"** 按钮

### 9.3 功能 1: 模型合并

**场景**: 合并多个优秀模型，获得更好的性能

#### 合并方法对比

| 方法 | 适用场景 | 优点 | 缺点 |
|------|----------|------|------|
| **Linear** | 2-3 个相似模型 | 简单稳定 | 可能降低性能 |
| **SLERP** | 2 个模型 | 保持模型"形状" | 只支持 2 个模型 |
| **TIES** | 多个微调模型 | 冲突解决好 | 计算复杂 |
| **DARE** | 3+ 模型 | 支持多模型 | 需要调参 |
| **SWA** | 同一训练的 checkpoints | 平滑权重 | 仅限同源模型 |

#### Step 1: 选择合并方法

```
合并方法: SLERP (推荐用于 2 个模型)
```

#### Step 2: 选择要合并的模型

**模型 A**:
```
路径: ./checkpoints/sft-sales-123/checkpoint-100
权重: 0.6 (60%)
描述: SFT 通用模型
```

**模型 B**:
```
路径: ./checkpoints/dpo-sales-456/checkpoint-50
权重: 0.4 (40%)
描述: DPO 对齐模型
```

💡 **权重说明**:
- 权重总和必须为 1.0
- 权重越大，该模型的影响越大
- 建议从 0.5:0.5 开始尝试

#### Step 3: 高级参数（可选）

**SLERP 参数**:
```
插值参数 t: 0.5 (0-1之间)
  - 0: 完全使用模型 A
  - 0.5: 均衡合并
  - 1: 完全使用模型 B
```

**TIES 参数**:
```
密度 (density): 0.8
  - 保留参数的比例
  - 越高保留越多，计算越慢
```

**DARE 参数**:
```
Drop Rate: 0.2
  - 随机丢弃参数的比例
  - 防止过拟合，增加泛化
```

#### Step 4: 配置输出

```
输出路径: ./checkpoints/merged/sft-dpo-merged
保存选项:
  ✓ 保存完整模型
  ✓ 保存合并日志
  □ 保存中间结果
```

#### Step 5: 开始合并

1. 点击 **"开始合并"** 按钮
2. 显示进度条

```
模型合并中...
┌─────────────────────────────────────────┐
│  进度: 60% ████████░░░░                  │
│  当前: 合并 layer 12/20                  │
│  耗时: 2 分钟                            │
│  预计剩余: 1 分钟                        │
└─────────────────────────────────────────┘
```

#### Step 6: 合并完成

```
✓ 模型合并完成！

合并结果:
├─ 输出路径: ./checkpoints/merged/sft-dpo-merged
├─ 模型大小: 980 MB
├─ 参数数量: 500M
├─ 合并方法: SLERP (t=0.5)
├─ 源模型:
│   ├─ 模型 A (60%): SFT 通用模型
│   └─ 模型 B (40%): DPO 对齐模型
└─ 耗时: 3 分 15 秒

下一步:
□ 评估合并后的模型
□ 使用合并模型进行推理
□ 继续训练合并模型
```

### 9.4 功能 2: 扫描最佳合并比例

**自动尝试不同比例，找到最佳配置**

#### Step 1: 配置扫描

```
模型 A: ./checkpoints/sft-sales-123/checkpoint-100
模型 B: ./checkpoints/dpo-sales-456/checkpoint-50

扫描范围: 0.0 - 1.0
扫描点数: 11 (每 0.1 一个点)
  → 生成 11 个合并模型
```

#### Step 2: 配置评估（可选）

```
✓ 对每个合并模型进行评估
评估数据集: 销售场景评估集
评估方法: 模型打分
```

#### Step 3: 开始扫描

```
扫描进度:
┌─────────────────────────────────────────┐
│  当前比例: 0.6 (模型 A : 模型 B)         │
│  已完成: 7/11                            │
│  当前评分: 4.35                          │
│  最佳比例: 0.5 (评分: 4.42)              │
└─────────────────────────────────────────┘
```

#### Step 4: 查看扫描结果

```
扫描结果:
┌──────────┬──────────┬──────────┬─────────┐
│  比例    │  模型A%  │  模型B%  │  评分   │
├──────────┼──────────┼──────────┼─────────┤
│  0.0     │  0%      │  100%    │  4.10   │
│  0.1     │  10%     │  90%     │  4.18   │
│  0.2     │  20%     │  80%     │  4.25   │
│  0.3     │  30%     │  70%     │  4.32   │
│  0.4     │  40%     │  60%     │  4.38   │
│  0.5     │  50%     │  50%     │  4.42 ⭐│
│  0.6     │  60%     │  40%     │  4.35   │
│  0.7     │  70%     │  30%     │  4.28   │
│  0.8     │  80%     │  20%     │  4.22   │
│  0.9     │  90%     │  10%     │  4.15   │
│  1.0     │  100%    │  0%      │  4.12   │
└──────────┴──────────┴──────────┴─────────┘

推荐比例: 0.5 (50% : 50%)
最佳评分: 4.42
```

**可视化曲线**:
```
评分 vs 合并比例:

4.5 │         ⭐
    │      ╱  │  ╲
4.3 │    ╱    │    ╲
    │  ╱      │      ╲
4.1 │╱        │        ╲
    └─────────┼─────────┼───→
    0.0      0.5       1.0
```

### 9.5 功能 3: Checkpoint 自动选择

**从多个 checkpoint 中自动选择最佳的**

#### Step 1: 选择训练任务

```
训练任务: SFT Sales Training (sft-sales-123)
可用 Checkpoints: 10 个
```

#### Step 2: 配置选择标准

```
选择标准:
  □ 最低 Loss
  ✓ 最佳验证性能
  □ 最新 Checkpoint
  ✓ 避免过拟合

过拟合检测:
  ✓ 训练 Loss 下降但验证 Loss 上升
  ✓ 验证准确率连续 3 次下降
```

#### Step 3: 评估所有 Checkpoints

```
评估进度:
┌─────────────────────────────────────────┐
│  已评估: 6/10                            │
│  当前: checkpoint-60                     │
│  当前最佳: checkpoint-80 (评分: 4.38)    │
└─────────────────────────────────────────┘
```

#### Step 4: 查看选择结果

```
Checkpoint 性能对比:
┌──────────────┬────────┬────────┬────────┬──────────┐
│ Checkpoint   │ Step   │ Loss   │ Val准确率│ 评估得分  │
├──────────────┼────────┼────────┼────────┼──────────┤
│ ckpt-20      │ 20     │ 3.245  │ 72%    │ 3.85     │
│ ckpt-40      │ 40     │ 2.876  │ 78%    │ 4.12     │
│ ckpt-60      │ 60     │ 2.543  │ 83%    │ 4.28     │
│ ckpt-80      │ 80     │ 2.312  │ 87%    │ 4.38 ⭐  │
│ ckpt-100     │ 100    │ 2.156  │ 85%⚠️  │ 4.25     │
│              │        │        │ ↓过拟合 │          │
└──────────────┴────────┴────────┴────────┴──────────┘

推荐 Checkpoint: checkpoint-80
理由:
  ✓ 验证准确率最高 (87%)
  ✓ 评估得分最高 (4.38)
  ✓ 未出现过拟合
  ⚠️ checkpoint-100 虽然训练 Loss 更低，但验证性能下降

操作:
  ☐ 使用 checkpoint-80 进行部署
  ☐ 删除其他 checkpoints 释放空间
```

### 9.6 功能 4: 权重平均 (SWA/EMA)

**平滑模型权重，提高稳定性**

#### SWA (Stochastic Weight Averaging)

**适用**: 同一训练的多个 checkpoints

```
选择 Checkpoints:
  ✓ checkpoint-60
  ✓ checkpoint-70
  ✓ checkpoint-80
  ✓ checkpoint-90
  ✓ checkpoint-100

平均方法: 等权重平均
输出路径: ./checkpoints/swa/swa-averaged

开始平均...

✓ 平均完成！
性能对比:
├─ checkpoint-100 (原始): 4.25
├─ SWA 平均: 4.32 (↑ 提升 1.6%)
└─ 更稳定，泛化性更好
```

#### EMA (Exponential Moving Average)

**适用**: 训练过程中的实时平均

```
选择训练任务: SFT Sales Training
起始 Step: 50
衰减率 (decay): 0.999
  - 越接近 1，历史权重影响越大
  - 推荐: 0.99 - 0.9999

开始计算 EMA...

✓ EMA 模型已生成
路径: ./checkpoints/ema/ema-decay-0.999
效果: 比最终 checkpoint 更平滑
```

### 9.7 功能 5: LoRA 合并

**将 LoRA 权重合并回基础模型**

#### Step 1: 选择 LoRA Checkpoint

```
基础模型: Qwen/Qwen2.5-0.5B
LoRA 权重: ./checkpoints/sft-lora-789/checkpoint-100
```

#### Step 2: 配置合并

```
合并方法: 完全合并
输出格式:
  ○ HuggingFace 格式
  ○ GGUF 格式 (用于推理)
  ○ SafeTensors 格式

输出路径: ./checkpoints/merged/sft-lora-merged
```

#### Step 3: 开始合并

```
合并 LoRA 权重...

✓ 合并完成！

结果:
├─ 基础模型大小: 980 MB
├─ LoRA 权重大小: 12 MB
├─ 合并后模型: 980 MB
├─ 性能保持: 100%
└─ 现在可以像普通模型一样使用
```

### 9.8 功能 6: 模型压缩（高级）

**减小模型大小，加速推理**

#### 方法 1: 量化

```
量化方法:
  ○ INT8 (8-bit) - 模型大小 1/4，略微降低精度
  ○ INT4 (4-bit) - 模型大小 1/8，精度下降明显
  ○ FP16 (16-bit) - 模型大小 1/2，精度几乎无损

选择: INT8
校准数据: 使用训练数据的子集 (100 样本)

开始量化...

✓ 量化完成！
├─ 原始模型: 980 MB
├─ 量化模型: 245 MB (↓ 75%)
├─ 精度损失: 0.3% (可接受)
└─ 推理速度: ↑ 2.5x
```

#### 方法 2: 剪枝

```
剪枝方法: 结构化剪枝
剪枝比例: 20% (删除 20% 的参数)
剪枝标准: 基于权重重要性

开始剪枝...

✓ 剪枝完成！
├─ 原始参数: 500M
├─ 剪枝后: 400M (↓ 20%)
├─ 精度损失: 1.2%
└─ 推理速度: ↑ 1.3x

建议: 剪枝后进行短期微调恢复精度
```

#### 方法 3: 蒸馏（高级）

```
教师模型: ./checkpoints/sft-large/checkpoint-100 (3B)
学生模型: Qwen/Qwen2.5-0.5B (0.5B)
蒸馏方法: Knowledge Distillation

蒸馏配置:
  温度 (Temperature): 2.0
  蒸馏损失权重: 0.5
  标签损失权重: 0.5
  训练步数: 1000

开始蒸馏...

✓ 蒸馏完成！
├─ 学生模型大小: 980 MB (教师模型 1/6)
├─ 性能: 达到教师模型 92%
├─ 推理速度: ↑ 5x
└─ 显存占用: ↓ 70%
```

### 9.9 批量操作

**对多个模型批量执行操作**

```
批量合并任务:

选择操作: 合并多个模型
选择模型:
  ✓ sft-sales-123/checkpoint-100
  ✓ dpo-sales-456/checkpoint-50
  ✓ grpo-math-789/checkpoint-80

合并策略:
  方法: TIES
  权重: [0.4, 0.3, 0.3]
  输出: ./checkpoints/merged/multi-model-merge

开始批量合并...

✓ 批量操作完成！
成功: 1   失败: 0
```

### 9.10 模型手术最佳实践

#### 推荐工作流

```
训练完成
    ↓
[Step 1] Checkpoint 自动选择
    ├─ 找到最佳 checkpoint
    ├─ 检测过拟合
    └─ 删除多余 checkpoints
    ↓
[Step 2] 权重平均 (可选)
    ├─ SWA/EMA 平滑权重
    └─ 提高泛化性
    ↓
[Step 3] 模型合并 (可选)
    ├─ 与其他优秀模型合并
    └─ 扫描最佳比例
    ↓
[Step 4] LoRA 合并 (如使用 LoRA)
    ├─ 合并 LoRA 权重
    └─ 生成完整模型
    ↓
[Step 5] 评估
    ├─ 对处理后的模型评估
    └─ 确认性能提升
    ↓
[Step 6] 压缩 (可选)
    ├─ 量化/剪枝
    └─ 优化部署
    ↓
部署使用
```

#### 常用组合

**组合 1: SFT + DPO 合并**
```
目的: 结合监督学习和偏好对齐
方法: SLERP (50:50)
效果: 性能 ↑ 5-10%
```

**组合 2: 多 Checkpoint 平均**
```
目的: 提高稳定性
方法: SWA (最后 5 个 checkpoints)
效果: 方差 ↓ 20%，泛化 ↑ 3%
```

**组合 3: LoRA 合并 + 量化**
```
目的: 部署优化
方法: 合并 LoRA → INT8 量化
效果: 大小 ↓ 75%，速度 ↑ 2.5x
```

---

## 完整训练流程

整合所有步骤，完整的端到端流程：

### 🎯 流程 1: 领域微调 (SFT)

```
Step 1: 准备环境
  ├─ 启动服务 (后端 + Celery + 前端)
  └─ 检查 GPU 可用

Step 2: 准备数据集
  ├─ 上传或使用现有数据集
  ├─ 验证数据格式
  ├─ 查看统计信息
  └─ (可选) 数据去重

Step 3: 创建训练任务
  ├─ 选择算法: SFT
  ├─ 配置模型和数据
  ├─ 配置训练参数
  ├─ 选择运行模式 (Local/SSH)
  └─ (可选) 启用 LoRA

Step 4: 开始训练
  └─ 提交任务

Step 5: 监控训练
  ├─ 查看实时 Metrics
  ├─ 查看日志
  └─ 等待完成

Step 6: Checkpoint 选择
  ├─ 评估所有 checkpoints
  └─ 选择最佳模型

Step 7: (可选) 权重平均
  └─ SWA 平滑最后几个 checkpoints

Step 8: 评估模型
  ├─ 创建评估任务
  ├─ 查看评估结果
  └─ 分析错误

Step 9: (可选) 模型压缩
  ├─ 量化到 INT8
  └─ 优化部署

Step 10: 部署使用
  └─ 使用训练好的模型
```

### 🎯 流程 2: RLHF 完整流程 (SFT → DPO → PPO)

```
阶段 1: SFT 基础训练
  ├─ Step 2: 准备 SFT 数据集
  ├─ Step 3: 创建 SFT 任务
  ├─ Step 5: 监控训练
  └─ 获得: sft-checkpoint-100

阶段 2: DPO 偏好对齐
  ├─ Step 2: 准备 DPO 偏好对数据
  ├─ Step 3: 创建 DPO 任务
  │   └─ 使用 sft-checkpoint-100 作为基础
  ├─ Step 5: 监控训练
  └─ 获得: dpo-checkpoint-50

阶段 3: PPO 强化学习
  ├─ Step 2: 准备 PPO prompt 数据
  ├─ Step 3: 创建 PPO 任务
  │   ├─ 使用 dpo-checkpoint-50 作为基础
  │   └─ 配置 Reward Model API
  ├─ Step 5: 监控训练
  └─ 获得: ppo-checkpoint-30

阶段 4: 模型合并（可选）
  ├─ Step 9: 合并 SFT + DPO + PPO
  │   ├─ 方法: TIES
  │   └─ 权重: [0.4, 0.3, 0.3]
  └─ 获得: merged-model

阶段 5: 评估与选择
  ├─ Step 8: 对比评估
  │   ├─ SFT 模型
  │   ├─ DPO 模型
  │   ├─ PPO 模型
  │   └─ 合并模型
  └─ 选择最佳模型

阶段 6: 部署
  ├─ Step 9: 压缩优化
  └─ 部署到生产环境
```

### 🎯 流程 3: 数学推理 (SFT → GRPO)

```
阶段 1: SFT 基础训练
  ├─ Step 2: 准备数学 SFT 数据
  ├─ Step 3: 创建 SFT 任务
  └─ 获得: sft-math-100

阶段 2: GRPO 推理优化
  ├─ Step 2: 准备 GRPO 数据 (问题+答案)
  ├─ Step 3: 创建 GRPO 任务
  │   ├─ 使用 sft-math-100 作为基础
  │   └─ 配置内置 reward function
  ├─ Step 5: 监控 reward_accuracy
  └─ 获得: grpo-math-80

阶段 3: 评估
  ├─ Step 8: 数学能力评估
  │   ├─ GSM8K 基准
  │   └─ 自定义数学题
  └─ 分析推理过程

阶段 4: 部署
  └─ 推理服务
```

---

## 💡 实用技巧

### 技巧 1: 快速验证数据

训练前快速检查数据：
```bash
# 检查 JSONL 格式
head -1 datasets/sales_sft.jsonl | jq .

# 统计行数
wc -l datasets/sales_sft.jsonl

# 检查字段
jq -r 'keys' datasets/sales_sft.jsonl | head -1
```

### 技巧 2: 评估时使用小样本

首次评估时使用小样本（10-20个）快速验证：
```
评估样本: 20 (从 100 中随机采样)
评估时间: 30 秒（而非 5 分钟）
快速了解模型表现
```

### 技巧 3: 合并前先扫描

不要直接合并，先扫描找最佳比例：
```
扫描点数: 11 (0.0 - 1.0)
找到最佳比例后再正式合并
```

### 技巧 4: 保留训练日志

所有训练日志都保存，方便回溯：
```bash
# 查看训练日志
tail -f logs/celery.log

# 保存日志
cp logs/celery.log logs/training-$(date +%Y%m%d).log
```

### 技巧 5: 使用 Pipeline 自动化

将完整流程（SFT → 评估 → DPO → 评估）封装成 Pipeline：
```
Pipeline: RLHF Complete Flow
├─ Stage 1: SFT Training
├─ Stage 2: SFT Evaluation
├─ Stage 3: DPO Training
├─ Stage 4: DPO Evaluation
└─ Stage 5: Model Merge
```

一键执行，自动完成！

---

## 📞 获取帮助

### 常见问题

**Q: 数据集上传失败？**
- 检查文件格式（JSONL/JSON）
- 检查文件大小（< 100MB 推荐）
- 检查文件编码（UTF-8）

**Q: 评估任务一直 PENDING？**
- 检查 Celery Worker 是否运行
- 检查 vLLM 是否正确安装
- 查看 Celery 日志

**Q: 模型合并失败？**
- 确保模型架构相同
- 检查磁盘空间是否充足
- 确保模型路径正确

**Q: LoRA 合并后性能下降？**
- 检查 LoRA 是否正确训练
- 尝试重新训练 LoRA（调整 rank）
- 检查基础模型版本是否匹配

### 文档链接

- [基础训练指南](./USER_GUIDE_TRAINING.md)
- [API 文档](http://localhost:8000/docs)
- [技术架构](./PHASE4_SUMMARY.md)

---

## 🎉 总结

完整训练流程包含：

1. ✅ **Step 2: 数据集管理** - 上传、验证、去重
2. ✅ **Step 3-7: 训练与监控** - 创建任务、实时监控
3. ✅ **Step 8: 自定义评估** - 多维度评估、对比分析
4. ✅ **Step 9: 模型手术** - 合并、选择、压缩、优化

现在你可以：
- 完整管理数据集生命周期
- 对模型进行全面评估
- 使用高级技术优化模型
- 实现端到端的训练部署流程

祝你训练顺利！🚀
