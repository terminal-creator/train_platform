#!/usr/bin/env python3
"""
å…¨ç®—æ³•è®­ç»ƒæµ‹è¯•

æµ‹è¯•æ‰€æœ‰æ”¯æŒçš„ç®—æ³•ï¼šSFT, PPO, GRPO, GSPO
ä½¿ç”¨ SSH è¿œç¨‹ GPU æœåŠ¡å™¨å’Œé˜¿é‡Œ Reward Model API
"""

import sys
import time
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from training_platform.core.database import (
    engine,
    Session,
    init_db,
    JobRepository,
    PipelineRepository,
    TrainingJob,
    Pipeline,
    PipelineStage,
    JobStatus,
    TrainingAlgorithm,
    PipelineStatus,
    PipelineStageStatus,
)
from training_platform.core.pipeline_executor import PipelineExecutor
from training_platform.core.ssh_runner import SSHConfig

# é¢œè‰²è¾“å‡º
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    END = '\033[0m'

def print_success(msg):
    print(f"{Colors.GREEN}âœ“ {msg}{Colors.END}")

def print_error(msg):
    print(f"{Colors.RED}âœ— {msg}{Colors.END}")

def print_info(msg):
    print(f"{Colors.BLUE}â„¹ {msg}{Colors.END}")

def print_section(title):
    print(f"\n{Colors.BLUE}{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}{Colors.END}\n")


# SSH é…ç½®ï¼ˆGPU æœåŠ¡å™¨ï¼‰
SSH_CONFIG = {
    "host": "connect.westc.gpuhub.com",
    "port": 27192,
    "username": "root",
    "password": "A32qbQ1UR3Y6",
    "working_dir": "~/verl_jobs",
}

# é˜¿é‡Œ Reward Model API
ALIBABA_RM_API_KEY = "sk-85ae32fc59d345e4ab1137f6bd3c3f10"
ALIBABA_RM_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"


def create_and_run_training(
    algorithm: TrainingAlgorithm,
    dataset_path: str,
    test_name: str,
    extra_config: dict = None,
) -> bool:
    """
    åˆ›å»ºå¹¶è¿è¡Œè®­ç»ƒä»»åŠ¡

    Args:
        algorithm: è®­ç»ƒç®—æ³•
        dataset_path: æ•°æ®é›†è·¯å¾„
        test_name: æµ‹è¯•åç§°
        extra_config: é¢å¤–é…ç½®å‚æ•°

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    timestamp = int(time.time())
    job_uuid = f"{algorithm.value}-job-{timestamp}"
    pipeline_uuid = f"{algorithm.value}-pipeline-{timestamp}"

    try:
        print_section(f"æµ‹è¯• {test_name}: {algorithm.value.upper()}")

        # ============== 1. åˆ›å»º Job ==============
        print_info(f"æ­¥éª¤ 1: åˆ›å»º {algorithm.value.upper()} Job")

        with Session(engine) as session:
            repo = JobRepository(session)

            job_config = {
                "uuid": job_uuid,
                "name": f"{test_name} {timestamp}",
                "description": f"{algorithm.value.upper()} è®­ç»ƒä»»åŠ¡",
                "status": JobStatus.PENDING,
                "algorithm": algorithm,
                "model_path": "Qwen/Qwen2.5-0.5B",
                "train_data_path": dataset_path,
                "num_gpus": 1,
                "learning_rate": 1e-5,
                "batch_size": 2,
                "num_epochs": 1,
                "context_length": 512,
                "warmup_steps": 5,
                "save_steps": 20,
                "eval_steps": 20,
            }

            # åˆå¹¶é¢å¤–é…ç½®
            if extra_config:
                job_config.update(extra_config)

            job = TrainingJob(**job_config)
            created_job = repo.create(job)

            print_success(f"Job åˆ›å»ºæˆåŠŸ: {job_uuid}")
            print_info(f"  ç®—æ³•: {algorithm.value}")
            print_info(f"  æ•°æ®é›†: {dataset_path}")

        # ============== 2. åˆ›å»º Pipeline ==============
        print_info("\næ­¥éª¤ 2: åˆ›å»º Pipeline")

        with Session(engine) as session:
            repo = PipelineRepository(session)

            pipeline = Pipeline(
                uuid=pipeline_uuid,
                name=f"{test_name} Pipeline {timestamp}",
                description=f"{algorithm.value.upper()} è®­ç»ƒæµç¨‹",
                status=PipelineStatus.PENDING,
            )
            repo.create(pipeline)

            # è®­ç»ƒé…ç½®
            train_config = {
                "num_gpus": 1,
                "batch_size": 2,
                "learning_rate": 1e-5,
            }

            # æ·»åŠ ç®—æ³•ç‰¹å®šé…ç½®
            if algorithm in [TrainingAlgorithm.PPO, TrainingAlgorithm.GRPO, TrainingAlgorithm.GSPO]:
                # RL ç®—æ³•éœ€è¦ reward model/function
                if algorithm == TrainingAlgorithm.PPO:
                    # PPO ä½¿ç”¨é˜¿é‡Œ API ä½œä¸º reward model
                    train_config.update({
                        "reward_model_type": "api",
                        "reward_model_api_base": ALIBABA_RM_BASE_URL,
                        "reward_model_api_key": ALIBABA_RM_API_KEY,
                        "kl_coef": 0.001,
                        "clip_ratio": 0.2,
                    })
                elif algorithm == TrainingAlgorithm.GRPO:
                    # GRPO ä½¿ç”¨å†…ç½® reward function
                    train_config.update({
                        "reward_fn_type": "math_verify",
                        "reward_fn_extract_answer": "boxed",
                        "reward_fn_compare_method": "exact",
                        "rollout_n": 5,
                    })
                elif algorithm == TrainingAlgorithm.GSPO:
                    # GSPO è‡ªåšå¼ˆ
                    train_config.update({
                        "reward_fn_type": "self_play",
                        "rollout_n": 5,
                    })

            # Pipeline stage
            stage_data = {
                "stage_name": "train",
                "task_name": "train_model",
                "task_params": {
                    "job_uuid": job_uuid,
                    "config": train_config,
                    "run_mode": "ssh",
                    "ssh_config": SSH_CONFIG,
                },
                "depends_on": [],
                "stage_order": 0,
            }

            stage = PipelineStage(
                pipeline_uuid=pipeline_uuid,
                **stage_data,
                status=PipelineStageStatus.PENDING,
            )
            repo.create_stage(stage)

            print_success(f"Pipeline åˆ›å»ºæˆåŠŸ: {pipeline_uuid}")

        # ============== 3. æ‰§è¡Œ Pipeline ==============
        print_info("\næ­¥éª¤ 3: æ‰§è¡Œ Pipeline")

        stages_config = [
            {
                "name": "train",
                "task": "train_model",
                "params": {
                    "job_uuid": job_uuid,
                    "config": train_config,
                    "run_mode": "ssh",
                    "ssh_config": SSH_CONFIG,
                },
                "depends_on": [],
            },
        ]

        executor = PipelineExecutor(pipeline_uuid)
        result = executor.execute(stages_config)

        print_success(f"Pipeline æäº¤æˆåŠŸ")
        print_info(f"  Task ID: {result.get('root_task_id')}")

        # ============== 4. ç›‘æ§çŠ¶æ€ ==============
        print_info("\næ­¥éª¤ 4: ç›‘æ§æ‰§è¡Œï¼ˆæœ€é•¿ 60 ç§’ï¼‰")

        max_wait_time = 60  # ç§’
        check_interval = 5  # ç§’
        checks = max_wait_time // check_interval

        for i in range(checks):
            time.sleep(check_interval)

            with Session(engine) as session:
                repo = PipelineRepository(session)
                job_repo = JobRepository(session)

                pipeline = repo.get_by_uuid(pipeline_uuid)
                job = job_repo.get_by_uuid(job_uuid)
                stages = repo.get_stages(pipeline_uuid)

                elapsed = (i + 1) * check_interval
                print_info(f"\n[{elapsed}ç§’] Pipeline: {pipeline.status.value}, Job: {job.status.value}")

                for stage in stages:
                    status_emoji = "âœ“" if stage.status == PipelineStageStatus.COMPLETED else (
                        "âœ—" if stage.status == PipelineStageStatus.FAILED else "â³"
                    )
                    print_info(f"  {status_emoji} Stage '{stage.stage_name}': {stage.status.value}")

                    if stage.error_message:
                        print_error(f"    é”™è¯¯: {stage.error_message[:150]}")

                # æ£€æŸ¥æ˜¯å¦å®Œæˆæˆ–å¤±è´¥
                if pipeline.status == PipelineStatus.COMPLETED:
                    print_success(f"\nâœ“ {algorithm.value.upper()} è®­ç»ƒæˆåŠŸå®Œæˆï¼")
                    return True
                elif pipeline.status == PipelineStatus.FAILED:
                    print_error(f"\nâœ— {algorithm.value.upper()} è®­ç»ƒå¤±è´¥")
                    return False

        # è¶…æ—¶
        print_info(f"\nâ± {algorithm.value.upper()} è®­ç»ƒä»åœ¨æ‰§è¡Œï¼ˆè¶…è¿‡ {max_wait_time} ç§’ç›‘æ§æ—¶é—´ï¼‰")

        with Session(engine) as session:
            job_repo = JobRepository(session)
            job = job_repo.get_by_uuid(job_uuid)

            if job.status == JobStatus.COMPLETED:
                print_success(f"âœ“ Job å·²å®Œæˆï¼ˆPipeline å¯èƒ½ä»åœ¨åå¤„ç†ï¼‰")
                return True
            elif job.status in [JobStatus.RUNNING, JobStatus.PENDING]:
                print_info(f"â„¹ Job ä»åœ¨è¿è¡Œä¸­")
                return True  # è®¤ä¸ºæˆåŠŸï¼ˆæ­£åœ¨æ‰§è¡Œï¼‰
            else:
                return False

    except Exception as e:
        print_error(f"{algorithm.value.upper()} æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰ç®—æ³•æµ‹è¯•"""
    print(f"\n{Colors.BLUE}")
    print("="*60)
    print("  å…¨ç®—æ³•è®­ç»ƒæµ‹è¯•")
    print("  GPU: RTX 5090 (32GB)")
    print("  RM API: é˜¿é‡Œ DashScope")
    print("="*60)
    print(f"{Colors.END}\n")

    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()

    # é…ç½®ç¯å¢ƒå˜é‡ï¼ˆé˜¿é‡Œ API Keyï¼‰
    os.environ["DASHSCOPE_API_KEY"] = ALIBABA_RM_API_KEY

    results = {}

    # æµ‹è¯• 1: SFT
    results["SFT"] = create_and_run_training(
        algorithm=TrainingAlgorithm.SFT,
        dataset_path="./datasets/sales_sft.jsonl",
        test_name="SFT Sales Training",
    )

    # æµ‹è¯• 2: PPO (ä½¿ç”¨é˜¿é‡Œ RM API)
    results["PPO"] = create_and_run_training(
        algorithm=TrainingAlgorithm.PPO,
        dataset_path="./datasets/ppo_general.json",
        test_name="PPO General Training",
    )

    # æµ‹è¯• 3: GRPO
    results["GRPO"] = create_and_run_training(
        algorithm=TrainingAlgorithm.GRPO,
        dataset_path="./datasets/sales_grpo.jsonl",
        test_name="GRPO Math Training",
    )

    # æµ‹è¯• 4: GSPO
    results["GSPO"] = create_and_run_training(
        algorithm=TrainingAlgorithm.GSPO,
        dataset_path="./datasets/sales_grpo.jsonl",  # GSPO å¯ä»¥ä½¿ç”¨ GRPO æ•°æ®
        test_name="GSPO Self-Play Training",
    )

    # æ±‡æ€»ç»“æœ
    print_section("æµ‹è¯•ç»“æœæ±‡æ€»")

    total = len(results)
    passed = sum(1 for v in results.values() if v)

    for algo_name, success in results.items():
        if success:
            print_success(f"{algo_name:10} âœ“ PASS")
        else:
            print_error(f"{algo_name:10} âœ— FAIL")

    print(f"\n{Colors.BLUE}æ€»è®¡: {passed}/{total} ç®—æ³•æµ‹è¯•é€šè¿‡{Colors.END}\n")

    if passed == total:
        print_success("ğŸ‰ æ‰€æœ‰ç®—æ³•è®­ç»ƒæˆåŠŸï¼")
        print_info("\nè¯¦ç»†ä¿¡æ¯:")
        print_info("  - SFT: ç›‘ç£å¾®è°ƒ")
        print_info("  - PPO: è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆä½¿ç”¨é˜¿é‡Œ RM APIï¼‰")
        print_info("  - GRPO: ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–")
        print_info("  - GSPO: ç»„è‡ªåšå¼ˆåå¥½ä¼˜åŒ–")
    else:
        print_error(f"éƒ¨åˆ†ç®—æ³•æµ‹è¯•å¤±è´¥ ({total - passed} ä¸ª)")

    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
